<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Spring Cloud Contract 实践]]></title>
    <url>%2F2019%2F08%2F30%2FSpring-Cloud-Contract-%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[Spring Cloud Contract 实践由于工作需要，第一次接触 Spring Cloud Contract 这个组件。中文翻译为 契约 ，它是一个用于微服务测试组件。在正常的微服务开发过程中，我们要进行测试时，通常情况下要启动全部的微服务项目，这个组件可以使我们在不启动其他微服务时完成测试。 什么是 Spring Cloud Contract在正常的情况下，我们的微服务是由数量众多的调用方服务与被调用方服务组成： 这种调用方式往往伴随着链式服务调用，如果想要测试左上角的服务，一般来说会有两个方法： 部署所有的微服务 在测试中模拟其他的微服务调用 这两种方式各有其优缺点。 部署所有的微服务 优点 可以模拟生产环境 测试服务之间的真实通信 缺点 需要启动所有的配套服务、数据库和其他关联项目 难以调试 在测试中模拟其他的微服务调用 优点 无需依赖于其他的服务 响应迅速 缺点 模拟服务的可靠性不足 为了解决以上的问题，Spring 推出了 Spring Cloud Contract ，主要的思想是提供快速的测试响应而无需配置其他的微服务。在引入 Spring Cloud Contract 后，应用的依赖关系会变为如下图所示： Spring Cloud Contract 用来保证所使用的的 stubs 是由被调用方创建及维护的。 实践Spring Cloud Contract 要求在被调用方声明并实现 契约 ，来由调用方进行使用。 Provider引入 Maven 依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-contract-verifier&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 引入 Maven 插件： 123456&lt;plugin&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-contract-maven-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud-contract.version&#125;&lt;/version&gt; &lt;extensions&gt;true&lt;/extensions&gt;&lt;/plugin&gt; 以 REST 形式编写 stubs 并实现，可以使用 Grovvy 或者 Yaml ，文件默认位于 /src/test/resources/contracts 目录下。 对于 HTTP stubs 需要指定路径、请求方法、状态码等信息，示例如下： 12345678910111213141516171819package contractsorg.springframework.cloud.contract.spec.Contract.make &#123; request &#123; url "/api" method GET() headers &#123; header(contentType(), applicationJsonUtf8()) &#125; &#125; response &#123; status OK() headers &#123; header(contentType(), applicationJsonUtf8()) &#125; body(["apple", "banana"]) &#125;&#125; 12345678910request: method: GET url: /api headers: Content-Type: application/json;charset=UTF-8response: status: 200 headers: Content-Type: application/json;charset=UTF-8 body: ["apple", "banana"] 指定测试基类： 1234567891011121314151617&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-contract-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.1.2.RELEASE&lt;/version&gt; &lt;extensions&gt;true&lt;/extensions&gt; &lt;configuration&gt; &lt;baseClassForTests&gt;com.hello.spring.cloud.contract.provider.HelloSpringCloudContractProviderApplicationTests&lt;/baseClassForTests&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 指定测试接口实例： 1234@Beforepublic void setUp() throws Exception &#123; RestAssuredMockMvc.standaloneSetup(new ApiController());&#125; 使用 ./mvnw clean install 自动生成测试并进行检验，生成的测试包默认在 target/generated-test-sources 目录下。自动生成的测试类如下： 1234567891011121314151617@Testpublic void validate_simpleProvider() throws Exception &#123; // given: MockMvcRequestSpecification request = given(); // when: ResponseOptions response = given().spec(request) .get("/api"); // then: assertThat(response.statusCode()).isEqualTo(200); assertThat(response.header("Content-Type")).isEqualTo("application/json;charset=UTF-8"); // and: DocumentContext parsedJson = JsonPath.parse(response.getBody().asString()); assertThatJson(parsedJson).arrayField().contains("apple").value(); assertThatJson(parsedJson).arrayField().contains("banana").value();&#125; 需要注意的是，必须要在测试基类中指定 MockMvc 实例，否则会报如下错误： 1234567891011java.lang.IllegalStateException: You haven&apos;t configured a MockMVC instance. You can do this staticallyRestAssuredMockMvc.mockMvc(..)RestAssuredMockMvc.standaloneSetup(..);RestAssuredMockMvc.webAppContextSetup(..);or using the DSL:given(). mockMvc(..). .. 当服务中包含多个 Controller 实例时，也可以使用如下配置： 1234567@Autowiredprivate WebApplicationContext context;@Beforepublic void setUp() throws Exception &#123; RestAssuredMockMvc.webAppContextSetup(context);&#125; Consumer添加 Maven 依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-contract-stub-runner&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 编写测试用例，使用 @AutoConfigureStubRunner 注解： 12345678910@RunWith(SpringRunner.class)@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.NONE)@AutoConfigureStubRunner( ids = &#123; "com.hello:hello-spring-cloud-contract-provider-groovy:+:stubs:8081", "com.hello:hello-spring-cloud-contract-provider-yaml:+:stubs:8082" &#125;, stubsMode = StubRunnerProperties.StubsMode.LOCAL)public class HelloSpringCloudContractConsumerApplicationTests &#123; 当 stubs 不在本地仓库时，使用如下方式从远程仓库获取 stubs ： 1234567891011@RunWith(SpringRunner.class)@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.NONE)@AutoConfigureStubRunner( ids = &#123; "com.hello:hello-spring-cloud-contract-provider-groovy:+:stubs:8081", "com.hello:hello-spring-cloud-contract-provider-yaml:+:stubs:8082" &#125;, repositoryRoot = "https://repo.spring.io/libs-snapshot", stubsMode = StubRunnerProperties.StubsMode.REMOTE)public class HelloSpringCloudContractConsumerApplicationTests &#123; 至此，Spring Cloud Contract 的基本功能已经全部实现。 总结Spring Cloud Contract 为我们在微服务测试过程中提供了一个有效的解决方法，可以说是微服务部分 TDD 的最佳实践。 参考文献： Spring Cloud Contract Reference Documentation]]></content>
      <categories>
        <category>Spring Cloud</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
        <tag>Test</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[idea的一些常用插件]]></title>
    <url>%2F2019%2F07%2F11%2Fidea%E7%9A%84%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E6%8F%92%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[jRebel: 热部署GsonFormat: json转pojomybatislombokGitToolBox]]></content>
      <categories>
        <category>IDEA</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[dnsmasq]]></title>
    <url>%2F2019%2F04%2F25%2Fdnsmasq%2F</url>
    <content type="text"><![CDATA[dnsmasq12345678910111213141516171819version: "3"services: dnsmasq: image: jpillora/dnsmasq:latest restart: always container_name: dnsmasq ports: - "53:53/udp" - "53:53/tcp" - "8100:8080" volumes: - ./conf/dnsmasq.conf:/etc/dnsmasq.conf:rw - ./conf/resolv.conf:/etc/resolv.conf:ro - ./conf/hosts:/etc/hosts:ro cap_add: - NET_ADMIN environment: - HTTP_USER=admin - HTTP_PASS=admin]]></content>
  </entry>
  <entry>
    <title><![CDATA[ELK]]></title>
    <url>%2F2019%2F04%2F25%2Felasticsearch%2F</url>
    <content type="text"><![CDATA[ELK1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253version: '3'services: elasticsearch: # image: docker.elastic.co/elasticsearch/elasticsearch:6.4.0 image: elasticsearch:6.4.0 restart: always container_name: elasticsearch dns: 47.93.241.176 environment: - discovery.type=single-node# - cluster.name=esCluster - bootstrap.memory_lock=true - "ES_JAVA_OPTS=-Xms512m -Xmx512m" ulimits: memlock: soft: -1 hard: -1 ports: - 9200:9200 - 9300:9300 volumes: - ./esdata/:/usr/share/elasticsearch/data/ - ./plugins/:/usr/share/elasticsearch/plugins/ kibana:# image: docker.elastic.co/kibana/kibana:6.4.0 image: kibana:6.4.0 restart: always container_name: kibana dns: 47.93.241.176 links: - elasticsearch depends_on: - elasticsearch# environment:# - SERVER_NAME=kibana# - ELASTICSEARCH_URL=http://elasticsearch:9200# - ELASTICSEARCH_USERNAME=elastic# - ELASTICSEARCH_PASSWORD=changeme ports: - 5601:5601 volumes: - ./kibana.yml:/usr/share/kibana/config/kibana.yml logstash:# image: docker.elastic.co/kibana/logstash:6.4.0 image: logstash:6.4.0 restart: always container_name: logstash dns: 47.93.241.176 command: logstash -f /usr/share/logstash/config/logstash-mysql.conf depends_on: - elasticsearch volumes: - ./config/:/usr/share/logstash/config/]]></content>
  </entry>
  <entry>
    <title><![CDATA[Nginx]]></title>
    <url>%2F2019%2F04%2F25%2Fnginx%2F</url>
    <content type="text"><![CDATA[Nginx123456789101112version: '3.4'services: nginx: restart: always image: nginx container_name: nginx # network_mode: host ports: - 80:80 volumes: - ./conf/nginx.conf:/etc/nginx/nginx.conf - ./wwwroot:/usr/share/nginx/wwwroot 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081worker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; client_max_body_size 0; server &#123; listen 80; server_name 192.168.80.135; location / &#123; add_header Access-Control-Allow-Origin *; add_header Access-Control-Allow-Headers X-Requested-With; add_header Access-Control-Allow-Methods GET,POST,OPTIONS; root /usr/share/nginx/wwwroot; index index.html index.htm; &#125; &#125; server &#123; listen 80; server_name git.orkva.com; location / &#123; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://192.168.80.135:8080; &#125; &#125; server &#123; listen 80; server_name hub.orkva.com; location / &#123; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://192.168.80.135:8082; &#125; &#125; server &#123; listen 80; server_name registry.orkva.com; location / &#123; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://192.168.80.135:5000; &#125; &#125; server &#123; listen 80; server_name mvn.orkva.com; location / &#123; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://47.93.241.176:8081; &#125; &#125;&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[OwnCloud]]></title>
    <url>%2F2019%2F04%2F25%2Fowncloud%2F</url>
    <content type="text"><![CDATA[OwnCloud123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172version: '2.1'volumes: files: driver: local mysql: driver: local backup: driver: local redis: driver: localservices: owncloud: image: owncloud/server:latest restart: always ports: - 8080:8080 depends_on: - db - redis environment: - OWNCLOUD_DOMAIN=www.orkva.com - OWNCLOUD_DB_TYPE=mysql - OWNCLOUD_DB_NAME=owncloud - OWNCLOUD_DB_USERNAME=owncloud - OWNCLOUD_DB_PASSWORD=owncloud - OWNCLOUD_DB_HOST=db - OWNCLOUD_ADMIN_USERNAME=admin - OWNCLOUD_ADMIN_PASSWORD=admin - OWNCLOUD_MYSQL_UTF8MB4=true - OWNCLOUD_REDIS_ENABLED=true - OWNCLOUD_REDIS_HOST=redis healthcheck: test: ["CMD", "/usr/bin/healthcheck"] interval: 30s timeout: 10s retries: 5 volumes: - files:/mnt/data db: image: webhippie/mariadb:latest restart: always environment: - MARIADB_ROOT_PASSWORD=owncloud - MARIADB_USERNAME=owncloud - MARIADB_PASSWORD=owncloud - MARIADB_DATABASE=owncloud - MARIADB_MAX_ALLOWED_PACKET=128M - MARIADB_INNODB_LOG_FILE_SIZE=64M healthcheck: test: ["CMD", "/usr/bin/healthcheck"] interval: 30s timeout: 10s retries: 5 volumes: - mysql:/var/lib/mysql - backup:/var/lib/backup redis: image: webhippie/redis:latest restart: always environment: - REDIS_DATABASES=1 healthcheck: test: ["CMD", "/usr/bin/healthcheck"] interval: 30s timeout: 10s retries: 5 volumes: - redis:/var/lib/redis]]></content>
  </entry>
  <entry>
    <title><![CDATA[空客]]></title>
    <url>%2F2019%2F04%2F20%2F%E7%A9%BA%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[空客一键安装脚本 SS V2Ray WireGuard]]></content>
  </entry>
  <entry>
    <title><![CDATA[IDEA中打开Dashboard]]></title>
    <url>%2F2019%2F01%2F30%2FIDEA%E6%89%93%E5%BC%80Dashboard%2F</url>
    <content type="text"><![CDATA[在 .idea 文件夹中的 workspace.xml 中找到 12345678910111213&lt;component name="RunDashboard"&gt; &lt;option name="ruleStates"&gt; &lt;list&gt; &lt;RuleState&gt; &lt;option name="name" value="ConfigurationTypeDashboardGroupingRule" /&gt; &lt;/RuleState&gt; &lt;RuleState&gt; &lt;option name="name" value="StatusDashboardGroupingRule" /&gt; &lt;/RuleState&gt; &lt;/list&gt; &lt;/option&gt; &lt;option name="contentProportion" value="0.28370553" /&gt;&lt;/component&gt; 然后在 Component 中添加下面的内容： 12345&lt;option name="configurationTypes"&gt; &lt;set&gt; &lt;option value="SpringBootApplicationConfigurationType" /&gt; &lt;/set&gt; &lt;/option&gt;]]></content>
      <categories>
        <category>IDEA</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Spring]]></title>
    <url>%2F2018%2F12%2F16%2Fspring%2F</url>
    <content type="text"><![CDATA[[TOC] Spring Framework Documentation Version 5.1.0.RELEASECoreQuickStart applicationContext.xml BeanFactory/ApplicationContext BeanFactory负责读取bean配置文档，管理bean的加载，实例化，维护bean之间的依赖关系，负责bean的声明周期。 ApplicationContext除了提供上述BeanFactory所能提供的功能之外，还提供了更完整的框架功能 Bean &lt;bean id=&quot;...&quot; class=&quot;...&quot;/&gt; scope : singleton|prototype|request|session|application|websocket lazy-init : 默认支持singleton 不支持prototype 构造方法: 无参/有参 静态工厂: &lt;bean id=&quot;...&quot; class=&quot;...&quot; factory-method=&quot;...&quot;/&gt; 实例工厂: &lt;bean id=&quot;...&quot; factory-bean=&quot;...&quot; factory-method=&quot;...&quot;/&gt; Dependency injection - 依赖注入 property: &lt;property name=&quot;...&quot; value|ref=&quot;...&quot;/&gt; constructor: &lt;constructor-arg index|name|type=&quot;...&quot; value|ref=&quot;...&quot;/&gt; p-namespace(property): &lt;bean id=&quot;...&quot; class=&quot;...&quot; p:driverClassName=&quot;...&quot; p:url=&quot;...&quot; p:username=&quot;...&quot; p:password=&quot;...&quot;/&gt; c-namespace(constructor): &lt;bean id=&quot;...&quot; class=&quot;...&quot; c:_0=&quot;...&quot; c:_1-ref=&quot;...&quot; c:name-ref=&quot;...&quot; c:email=&quot;...&quot;/&gt; EL(Expression Language): &lt;property name=&quot;...&quot; value=&quot;#{&lt;expression&gt;}&quot;/&gt; # 是spring提供的EL表达式，用于获取对象的属性与方法 $ 用于获取引入的properties文件中key的对应变量的值 复合类型: &lt;property name=&quot;dataSource.driverClassName&quot; value|ref=&quot;...&quot;/&gt; Annotation @Component|@Repository|@Service|@Controller @Autowired|@Inject|@Resource|@Value @Scope @Required|@Primary|@Qualifier @PostConstruct|@PreDestroy @ComponentScan JUnit4 @RunWith(SpringJunit4ClassRunner.class) @ContextConfiguration context:annotation-config在基于主机方式配置Spring时,Spring配置文件applicationContext.xml,你可能会见 &lt;context:annotation-config/&gt; 这样一条配置，它的作用是隐式的向Spring容器注册 AutowiredAnnotationBeanPostProcessor CommonAnnotationBeanPostProcessor PersistenceAnnotationBeanPostProcessor RequiredAnnotationBeanPostProcessor 这4个BeanPostProcessor。注册这4个bean处理器主要的作用是为了你的系统能够识别相应的注解。 使用@Autowired注解，需声明AutowiredAnnotationBeanPostProcessor。 使用@PersistenceContext注解，需声明PersistenceAnnotationBeanPostProcessor。 使用@Required注解，需声明RequiredAnnotationBeanPostProcessor。 使用@Resource、@PostConstruct、@PreDestroy等注解须声明CommonAnnotationBeanPostProcessor。 context:component-scan它的base-package属性指定了需要扫描的类包，类包及其递归子包中所有的类都会被处理。 使用 &lt;context：component-scan&gt; 隐式启用 &lt;context：annotation-config&gt; 的功能。使用 &lt;context：component-scan&gt; 时，通常不需要包含 &lt;context：annotation-config&gt; 元素。 AOP Spring AOP代理机制 JDK动态代理: 针对实现了接口的类 CGLib动态代理: 针对没有实现接口的类，应用最底层的字节码增强技术生成当前类的子类对象 术语 Joinpoint(连接点): 被拦截的点，在spring中，这些点指的是方法，因为spring只支持方法类型的连接点（可以切入的点） Pointcut(切入点): 对哪些Joinpoint进行拦截的定义。（已经被切入的点） Advice(通知/增强): 拦截到Joinpoint之后所要做的事情就是通知。通知分为前置通知、后置通知、异常通知、最终通知、环绕通知（切面要完成的功能） Introduction(引介): 一种特殊的通知，在不修改类代码的前提下，Introduction可以在运行期为类动态地添加一些方法或Field。 Aspect(切面): Pointcut和Advice|Introduction的结合 Target(目标对象): 代理的目标对象 Proxy(代理): 一个类被AOP织入增强后，就产生了一个结果代理类。 Weaving(织入): 将增强应用到目标对象来创建新的代理对象的过程。spring采用动态代理织入，而AspectJ采用编译期织入和类装载期织入 aop:config, aop:pointcut, aop:aspect, aop:before|after|after-returning|after-throwing|around &lt;aop:aspectj-autoproxy/&gt;, @Aspect, @Pointcut, @Before, @After, @AfterReturning, @AfterThrowing, @Around pointcut public * *(..): 任何public方法 * set*(..): 任何set方法 * com.xyz.service.UserService.(..): com.xyz.service.UserService类的任何方法 * com.xyz.service.*.(..): com.xyz.service包下任何方法 * com.xyz.service..*.(..): com.xyz.service包及其子包下任何方法 Data Access/IntegrationJdbcTemplate &lt;bean id=&quot;jdbcTemplate&quot; class=&quot;org.springframework.jdbc.core.JdbcTemplate&quot; p:dataSource-ref=&quot;dataSource&quot;/&gt; Transaction 事务隔离 一个数据库事务通常包含了一个序列的对数据库的读/写操作。它的存在包含有以下两个目的： 为数据库操作序列提供了一个从失败中恢复到正常状态的方法，同时提供了数据库即使在异常状态下仍能保持一致性的方法。 当多个应用程序在并发访问数据库时，可以在这些应用程序之间提供一个隔离方法，以防止彼此的操作互相干扰。 并非任意的对数据库的操作序列都是数据库事务。数据库事务拥有以下四个特性，习惯上被称之为ACID特性。 原子性（Atomicity）：事务作为一个整体被执行，包含在其中的对数据库的操作要么全部被执行，要么都不执行。 一致性（Consistency）：事务应确保数据库的状态从一个一致状态转变为另一个一致状态。一致状态的含义是数据库中的数据应满足完整性约束。 隔离性（Isolation）：多个事务并发执行时，一个事务的执行不应影响其他事务的执行。 持久性（Durability）：已被提交的事务对数据库的修改应该永久保存在数据库中。 事务隔离（英语：Transaction Isolation）定义了数据库系统中一个操作的结果在何时以何种方式对其他并发操作可见。隔离是事务ACID四大属性之一。 ANSI/ISO SQL定义的标准隔离级别如下： 可串行化（SERIALIZABLE） 最高的隔离级别。 在基于锁机制并发控制的DBMS实现可串行化，要求在选定对象上的读锁和写锁保持直到事务结束后才能释放。在SELECT的查询中使用一个“WHERE”子句来描述一个范围时应该获得一个“范围锁”（range-locks）。这种机制可以避免“幻影读”（phantom reads）现象（详见下文）。 当采用不基于锁的[并发控制]时不用获取锁。但当系统探测到几个并发事务有“写冲突”的时候，只有其中一个是允许提交的。这种机制的详细描述见“快照隔离” 可重复读（REPEATABLE READS） 在可重复读隔离级别中，基于锁机制并发控制的DBMS需要对选定对象的读锁（read locks）和写锁（write locks）一直保持到事务结束，但不要求“范围锁”，因此可能会发生“幻影读”。 提交读（READ COMMITTED） 在提交读级别中，基于锁机制并发控制的DBMS需要对选定对象的写锁一直保持到事务结束，但是读锁在SELECT操作完成后马上释放（因此“不可重复读”现象可能会发生，见下面描述）。和前一种隔离级别一样，也不要求“范围锁”。 未提交读（READ UNCOMMITTED） 未提交读是最低的隔离级别。允许“脏读”（dirty reads），事务可以看到其他事务“尚未提交”的修改。 通过比低一级的隔离级别要求更多的限制，高一级的级别提供更强的隔离性。标准允许事务运行在更强的事务隔离级别上。(如在可重复读隔离级别上执行提交读的事务是没有问题的) 读现象 脏读 当一个事务允许读取另外一个事务修改但未提交的数据时，就可能发生脏读。 脏读和不可重复读（non-repeatable reads）类似。事务2没有提交造成事务1的语句1两次执行得到不同的结果集。在未提交读隔离级别唯一禁止的是更新混乱，即早期的更新可能出现在后来更新之前的结果集中。 不可重复读在一次事务中，当一行数据获取两遍得到不同的结果表示发生了“不可重复读”. 在基于锁的并发控制中“不可重复读”现象发生在当执行SELECT 操作时没有获得读锁或者SELECT操作执行完后马上释放了读锁； 多版本并发控制中当没有要求一个提交冲突的事务回滚也会发生“不可重复读”现象。 幻影读在事务执行过程中，当两个完全相同的查询语句执行得到不同的结果集。这种现象称为“幻影读（phantom read）” 当事务没有获取范围锁的情况下执行SELECT … WHERE操作可能会发生“幻影读”。 “幻影读”是不可重复读的一种特殊场景：当事务1两次执行SELECT … WHERE检索一定范围内数据的操作中间，事务2在这个表中创建了(如INSERT)了一行新数据，这条新数据正好满足事务1的“WHERE”子句。 隔离级别vs读现象 | 隔离级别 | 脏读 | 不可重复读 | 幻影读 || :——: | :——: | :——–: | :——: || 未提交读 | 可能发生 | 可能发生 | 可能发生 || 提交读 | - | 可能发生 | 可能发生 || 可重复读 | - | - | 可能发生 || 可序列化 | - | - | - | 可序列化（Serializable）隔离级别不等同于可串行化（Serializable）。可串行化调度是避免以上三种现象的必要条件，但不是充分条件。“可能发生”表示这个隔离级别会发生对应的现象，“-”表示不会发生。 隔离级别vs锁持续时间 在基于锁的并发控制中，隔离级别决定了锁的持有时间。“C”-表示锁会持续到事务提交。 “S” –表示锁持续到当前语句执行完毕。如果锁在语句执行完毕就释放则另外一个事务就可以在这个事务提交前修改锁定的数据，从而造成混乱。 | 隔离级别 | 写操作 | 读操作 | 范围操作 (…where…) || :——: | :—-: | :—-: | :——————–: || 未提交读 | S | S | S || 提交读 | C | S | S || 可重复读 | C | C | S || 可序列化 | C | C | C | 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586package org.springframework.transaction;public interface TransactionDefinition &#123;、 /** * 默认的spring事务传播级别 * 如果上下文中已经存在事务，那么就加入到事务中执行，如果当前上下文中不存在事务，则新建事务执行。 */ int PROPAGATION_REQUIRED = 0; /** * 如果上下文存在事务，则支持事务加入事务，如果没有事务，则使用非事务的方式执行。 */ int PROPAGATION_SUPPORTS = 1; /** * 要求上下文中必须要存在事务，否则就会抛出异常。 */ int PROPAGATION_MANDATORY = 2; /** * 每次都会新建一个事务，并且同时将上下文中的事务挂起，执行当前新建事务完成以后，上下文事务恢复再执行。 */ int PROPAGATION_REQUIRES_NEW = 3; /** * 不支持事务。上下文中存在事务，则挂起事务，执行当前逻辑，结束后恢复上下文的事务。 */ int PROPAGATION_NOT_SUPPORTED = 4; /** * 要求上下文中不能存在事务，一旦有事务，就抛出异常。 */ int PROPAGATION_NEVER = 5; /** * 如果上下文中存在事务，则嵌套事务执行，如果不存在事务，则新建事务。 */ int PROPAGATION_NESTED = 6; /** * 默认的隔离级别 * 使用数据库默认的事务隔离级别。 */ int ISOLATION_DEFAULT = -1; /** * 读未提交 */ int ISOLATION_READ_UNCOMMITTED = 1; /** * 读已提交 */ int ISOLATION_READ_COMMITTED = 2; /** * 可重复读 */ int ISOLATION_REPEATABLE_READ = 4; /** * 串行化 */ int ISOLATION_SERIALIZABLE = 8; /** * 默认-1，不超时 */ int TIMEOUT_DEFAULT = -1; /** * 获取事务传播行为 * @return */ int getPropagationBehavior(); /** * 获取事务隔离级别 * @return */ int getIsolationLevel(); /** * 获取事务超时时间 * @return */ int getTimeout(); /** * 是否只读事务 * @return */ boolean isReadOnly(); String getName();&#125; 123&lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource"/&gt;&lt;/bean&gt; 12345&lt;tx:advice id="transactionInterceptor" transaction-manager="transactionManager"&gt; &lt;tx:attributes&gt; &lt;tx:method name="transfer" propagation="REQUIRED"/&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt; 1234&lt;aop:config&gt; &lt;aop:pointcut id="transactionPointcut" expression="execution(* com.shieh.service..*.*(..))"/&gt; &lt;aop:advisor advice-ref="transactionInterceptor" pointcut-ref="transactionPointcut"/&gt;&lt;/aop:config&gt; 使用 &lt;tx:annotation-driven/&gt; 开启事务注解,使用 @Transactional 在业务层声明事务 WebQuickStart 123456789101112131415&lt;!-- web.xml --&gt;&lt;servlet&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:dispatcherServlet.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 12345&lt;!-- dispatcherServlet.xml --&gt;&lt;bean class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="prefix" value="/WEB-INF/jsp/"/&gt; &lt;property name="suffix" value=".jsp"/&gt;&lt;/bean&gt; 123456789101112131415161718192021222324&lt;!-- pom.xml --&gt;&lt;!-- 编译插件 --&gt;&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.7.0&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt;&lt;/plugin&gt;&lt;!-- Tomcat插件 --&gt;&lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;port&gt;8080&lt;/port&gt; &lt;path&gt;/spring-mvc&lt;/path&gt; &lt;uriEncoding&gt;UTF-8&lt;/uriEncoding&gt; &lt;warSourceDirectory&gt;$&#123;basedir&#125;/target/$&#123;project.artifactId&#125;&lt;/warSourceDirectory&gt; &lt;/configuration&gt;&lt;/plugin&gt; Annotation @RequestMapping @GetMapping,@PostMapping,@PutMapping,@DeleteMapping,@PatchMapping glob 模式和通配符映射请求,使用@PathVariable获取 ? 匹配一个字符 * 匹配路径段中的零个或多个字符 ** 匹配零个或多个路径段 consumes: 根据请求缩小请求映射范围Content-Type 该consumes属性还支持否定表达式 - 例如，!text/plain表示除了以外的任何内容类型text/plain。 MediaType提供常用媒体类型的常量，例如 APPLICATION_JSON_VALUE和APPLICATION_XML_VALUE。 produces: 根据Accept请求标头和控制器方法生成的内容类型列表来缩小请求映射 媒体类型可以指定字符集。支持否定表达式 params: 根据请求参数条件缩小请求映射 headers: 根据请求头条件缩小请求映射 @PathVariable 使用{varName:regex}进行正则匹配 @RequestParam，@RequestHeader，@RequestAttribute @RequestParam 用于获取从表单传递的参数 @RequestAttribute 用于获取请求转发时设置的属性 @SessionAttributes,@SessionAttribute,@CookieValue POST乱码 1234567891011121314151617&lt;!-- web.xml --&gt;&lt;filter&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; GET乱码&lt;uriEncoding&gt;UTF-8&lt;/uriEncoding&gt; RESTful表现层状态转换（REST，英文：Representational State Transfer）是Roy Thomas Fielding博士于2000年在他的博士论文中提出来的一种万维网软件架构风格，目的是便于不同软件/程序在网络（例如互联网）中互相传递信息。 需要注意的是，REST是设计风格而不是标准。REST通常基于使用HTTP，URI，和XML以及HTML这些现有的广泛流行的协议和标准。 资源是由URI来指定。 对资源的操作包括获取、创建、修改和删除资源，这些操作正好对应HTTP协议提供的GET、POST、PUT和DELETE方法。 通过操作资源的表现形式来操作资源。 资源的表现形式则是XML或者HTML，取决于读者是机器还是人，是消费web服务的客户软件还是web浏览器。当然也可以是任何其他的格式。 浏览器 form 表单只支持 GET 与 POST 请求，而 DELETE、PUT 等 method 并不支持，spring3.0 添加了一个过滤器，可以将这些请求转换为标准的 http 方法，使得支持 GET、POST、PUT 与 DELETE 请求，该过滤器为HiddenHttpMethodFilter。 HiddenHttpMethodFilter 只对 POST 请求的表单进行过滤，在表单内部添加 name=&quot;_method&quot; 进行类型声明。 1234&lt;form action="..." method="POST"&gt; &lt;input type="hidden" name="_method" value="DELETE"/&gt; ......&lt;/form&gt; 排除静态资源 使用&lt;mvc:default-servlet-handler/&gt;指定默认处理器处理静态资源 单独使用会让所有访问都进行默认处理，导致@RequestMapping注解失效，需要配合&lt;mvc:annotation-driven/&gt;使用 使用&lt;mvc:resources/&gt;指定静态资源匹配规则 123&lt;mvc:resources mapping="/resources/**" location="/public, classpath:/static/" cache-period="31556926" /&gt; 在web.xml进行配置默认servlet 12345678910111213141516171819202122232425262728&lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;*.css&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;*.gif&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;*.mp4&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;*.png&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;*.jpg&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;*.js&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;*.html&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; url-pattern url-pattern 中 / 与 /* 的区别，参考Difference between / and /* in servlet mapping url pattern / 表示匹配所有路径，例如 /login ，它覆盖容器的默认Servlet的映射 /* 表示匹配所有的路径及资源，例如 /login ， *.jsp mvc:annotation-driven &lt;mvc:annotation-driven/&gt; 是一种简写形式，其声明会自动注册 DefaultAnnotationHandlerMapping和AnnotationMethodHandlerAdapter 两个Bean，是Spring MVC为@Controllers分发请求所必需的 同时它还提供了数据绑定支持，@NumberFormatannotation支持，@DateTimeFormat支持，@Valid支持，读写XML的支持（JAXB），读写JSON的支持（Jackson） 使用其子标签&lt;mvc:path-matching&gt;为Spring MVC提供路径匹配模式，默认情况下/index和/index.xxx都可以到@RequestMapping(&quot;/index&quot;)，使用&lt;mvc:path-matching suffix-pattern=&quot;false&quot;/&gt;强制进行路径匹配 DefaultAnnotationHandlerMapping和AnnotationMethodHandlerAdapter 在Spring 3.2版本中已声明弃用，在Spring 3.2 及以上版本中建议使用 RequestMappingHandlerMapping 与 RequestMappingHandlerAdapter 类型转换 默认情况下Spring MVC会使用格式化程序将请求数据转换为对象，Spring MVC内部已经实现了 Number 与 Date 类型的转换规则，需要使用时可以在字段上添加 @NumberFormat 和 @DateTimeFormat 注解 同时它也支持自定义格式化程序和转换器，实现 Converter 接口，并在 SpringConfig.xml 中进行配置 123456789101112131415161718192021&lt;mvc:annotation-driven conversion-service="conversionService"/&gt;&lt;bean id="conversionService" class="org.springframework.format.support.FormattingConversionServiceFactoryBean"&gt; &lt;property name="converters"&gt; &lt;set&gt; &lt;bean class="org.example.MyConverter"/&gt; &lt;/set&gt; &lt;/property&gt; &lt;property name="formatters"&gt; &lt;set&gt; &lt;bean class="org.example.MyFormatter"/&gt; &lt;bean class="org.example.MyAnnotationFormatterFactory"/&gt; &lt;/set&gt; &lt;/property&gt; &lt;property name="formatterRegistrars"&gt; &lt;set&gt; &lt;bean class="org.example.MyFormatterRegistrar"/&gt; &lt;/set&gt; &lt;/property&gt;&lt;/bean&gt; JSON请求 使用@RequestBody传递请求参数 使用@ResponseBody返回处理结果 异常处理 @ExceptionHandler 结合@ControllerAdvice使用 参考@ExceptionHandler方法 拦截器所有HandlerMapping实现都支持处理程序拦截器，这些拦截器在您要将特定功能应用于某些请求时很有用 - 例如，检查主体。拦截器必须HandlerInterceptor从 org.springframework.web.servlet包中实现三种方法，这些方法应该提供足够的灵活性来进行各种预处理和后处理： preHandle(..)：在执行实际处理程序之前 postHandle(..)：处理程序执行后 afterCompletion(..)：完成请求完成后 该preHandle(..)方法返回一个布尔值。您可以使用此方法来中断或继续执行链的处理。当此方法返回时true，处理程序执行链继续。当它返回false时，DispatcherServlet 假定拦截器本身已处理请求（并且，例如，呈现适当的视图）并且不继续执行执行链中的其他拦截器和实际处理程序。 见拦截在MVC配置一节的如何配置拦截器的实例。您也可以通过在各个HandlerMapping实现上使用setter直接注册它们 。 请注意，postHandle对于在之前和之前 编写和提交响应的方法@ResponseBody和ResponseEntity方法不太有用。这意味着对响应进行任何更改都为时已晚，例如添加额外的标头。对于此类方案，您可以实现并将其声明为Controller Advice bean或直接对其进行配置 。HandlerAdapter postHandle ResponseBodyAdvice RequestMappingHandlerAdapter 文件上传 123456&lt;!-- pom.xml --&gt;&lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt;&lt;/dependency&gt; 123456789&lt;!-- SpringConfig.xml --&gt;&lt;!-- 必须配置id --&gt;&lt;bean id="multipartResolver" class="org.springframework.web.multipart.commons.CommonsMultipartResolver"&gt; &lt;!--默认 ISO-8859-1--&gt; &lt;property name="defaultEncoding" value="UTF-8"/&gt; &lt;property name="maxInMemorySize" value="10240"/&gt; &lt;property name="uploadTempDir" value="/upload/"/&gt; &lt;property name="maxUploadSize" value="-1"/&gt;&lt;/bean&gt; 1234&lt;form action="$&#123;pageContext.request.contextPath&#125;/fileupload" method="post" enctype="multipart/form-data"&gt; &lt;input type="file" name="file"&gt; ...&lt;/form&gt; 123456789101112@PostMapping("/form")public String handleFormUpload(@RequestParam("name") String name, @RequestParam("file") MultipartFile file) &#123; if (!file.isEmpty()) &#123; byte[] bytes = file.getBytes(); // store the bytes somewhere return "redirect:uploadSuccess"; &#125; return "redirect:uploadFailure";&#125; SpringBoot排除自动装配1@SpringBootApplication(exclude = &#123;DataSourceAutoConfiguration.class&#125;)]]></content>
  </entry>
  <entry>
    <title><![CDATA[前端框架]]></title>
    <url>%2F2018%2F11%2F14%2F%E5%89%8D%E7%AB%AF%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[jQuery Validation 表单验证插件 jQuery iCheck 复选/单选美化插件 jQuery Datatables 表格插件 jQuery TreeTable 树表格插件 jQuery zTree 树形结构插件 Dropzone 图片上传插件 wangEditor 富文本编辑器 SiteMesh： 是一个Web页面布局、装饰以及与现有Web应用整合的框架。]]></content>
  </entry>
  <entry>
    <title><![CDATA[动态代理]]></title>
    <url>%2F2018%2F11%2F14%2F%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[动态代理 所谓动态代理，即通过代理类：Proxy的代理，接口和实现类之间可以不直接发生联系，而可以在运行期（Runtime）实现动态关联。 java动态代理主要是使用 java.lang.reflect 包中的两个类。 InvocationHandler类 public Object invoke(Object proxy, Method method, Object[] args) throws Throwable proxy是代理类，method是被代理的方法，args是被代理方法的参数。此方法由代理类实现。 Proxy类 protected Proxy(InvocationHandler h) public static Class&lt;?&gt; getProxyClass(ClassLoader loader, Class&lt;?&gt;... interfaces) throws IllegalArgumentException public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException 动态代理其实是在运行时生成class，所以，必须为其提供一组interface，然后告诉他class已经实现了这些interface，而且在生成Proxy的时候，必须给他提供一个handler，让他来接管实际的工作。 12345678910111213141516171819202122232425262728/** * 用于动态生成一个代理对象 */public class CreateProxy implements InvocationHandler &#123; private Object target; // 被代理的对象 // 用于创建代理对象的方法 public Object create(Object target) &#123; this.target = target; return Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), this); &#125; /** * 代理对象要执行的方法 * @param proxy 代理类对象 * @param method 被代理对象的方法 * @param args 被代理对象方法的参数 * @return * @throws Throwable */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println("==&gt; 开始代理 &lt;=="); Object invoke = method.invoke(target, args); System.out.println("==&gt; 结束代理 &lt;=="); return invoke; &#125;&#125; 123456789/** * 接口实现类 */public class Person implements Runnable &#123; @Override public void run() &#123; System.out.println("核心业务"); &#125;&#125; 12345678public class MainClass &#123; public static void main(String[] args) &#123; CreateProxy createProxy = new CreateProxy(); // 用来创建代理对象的对象 Runnable person = new Person(); Runnable proxy = (Runnable) createProxy.create(person); proxy.run(); // inovke &#125;&#125; 1234567891011121314/** * 接口实现类 */public class Person implements Runnable, Consumer&lt;String&gt; &#123; @Override public void run() &#123; System.out.println("核心业务"); &#125; @Override public void accept(String s) &#123; System.out.println("另一个核心业务:" + s); &#125;&#125; 1234567891011public class MainClass &#123; public static void main(String[] args) &#123; CreateProxy createProxy = new CreateProxy(); // 用来创建代理对象的对象 Person person = new Person(); Object proxy = createProxy.create(person); Runnable runnableProxy = (Runnable) proxy; runnableProxy.run(); // inovke Consumer consumerProxy = (Consumer) proxy; consumerProxy.accept("核心业务"); &#125;&#125; 动态代理应用：AOP框架的简单实现1234567public class Message implements Consumer&lt;String&gt; &#123; private List&lt;String&gt; list = new ArrayList&lt;&gt;(); @Override public void accept(String s) &#123; list.add(s); &#125;&#125; 1234public interface Advice &#123; void beforeAdvice(); void afterAdvice();&#125; 1234567891011121314/** * 切面的实现类 */public class LogAdvice implements Advice &#123; @Override public void beforeAdvice() &#123; System.out.println("start time:" + System.currentTimeMillis()); &#125; @Override public void afterAdvice() &#123; System.out.println("end time:" + System.currentTimeMillis()); &#125;&#125; 123bean.target=Messagebean.advice=LogAdvicebean=ProxyFactoryBean 1234567891011121314151617181920212223242526public class ProxyFactoryBean implements InvocationHandler &#123; private Object target; private Advice advice; public Object getProxy() &#123; return Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), this); &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; advice.beforeAdvice(); Object obj = method.invoke(target, args); advice.afterAdvice(); return obj; &#125; public Object getTarget() &#123; return target; &#125; public void setTarget(Object target) &#123; this.target = target; &#125; public Advice getAdvice() &#123; return advice; &#125; public void setAdvice(Advice advice) &#123; this.advice = advice; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class BeanFactory &#123; private Properties prop = new Properties(); public BeanFactory(InputStream in) &#123; try &#123; prop.load(in); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public Object getBean(String name) &#123; String className = prop.getProperty(name); Object bean = null; try &#123; // 获取ProxyFactoryBean的class对象 Class&lt;?&gt; aClass = Class.forName(className); bean = aClass.newInstance(); // 实例化对象 // 根据配置文件实例化target和advice对象 Object target = Class.forName(prop.getProperty(name.concat(".target"))).newInstance(); Object advice = Class.forName(prop.getProperty(name.concat(".advice"))).newInstance(); // 通过内省实现对ProxyFactoryBean的属性赋值 BeanInfo beanInfo = Introspector.getBeanInfo(aClass); PropertyDescriptor[] propertyDescriptors = beanInfo.getPropertyDescriptors(); for (PropertyDescriptor propertyDescriptor : propertyDescriptors) &#123; String propertyName = propertyDescriptor.getName(); Method writeMethod = propertyDescriptor.getWriteMethod(); if ("target".equals(propertyName)) &#123; writeMethod.invoke(bean, target); &#125; else if ("advice".equals(propertyName)) &#123; writeMethod.invoke(bean, advice); &#125; &#125; &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; catch (InstantiationException e) &#123; e.printStackTrace(); &#125; catch (IntrospectionException e) &#123; e.printStackTrace(); &#125; catch (InvocationTargetException e) &#123; e.printStackTrace(); &#125; return bean; &#125;&#125; 123456789101112public class MainClass &#123; public static void main(String[] args) &#123; // 1. 读取配置文件 InputStream in = ClassLoader.getSystemResourceAsStream("bean.properties"); // 2. 创建bean的工厂对象 BeanFactory beanFactory = new BeanFactory(in); // 3. 获取代理对象 ProxyFactoryBean proxyFactoryBean = (ProxyFactoryBean) beanFactory.getBean("bean"); Consumer&lt;String&gt; proxy = (Consumer&lt;String&gt;) proxyFactoryBean.getProxy(); proxy.accept("Tom"); &#125;&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[Dropzone 图片上传插件]]></title>
    <url>%2F2018%2F11%2F13%2FDropzone%20%E5%9B%BE%E7%89%87%E4%B8%8A%E4%BC%A0%E6%8F%92%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[Dropzone 图片上传插件Dropzone 简介Dropzone 是一个开源的 JavaScript 库，提供文件的异步上传功能，并支持拖拽上传功能 页面引用CSS 部分，其中 basic.min.css 提供了官网的炫酷上传效果 12&lt;link rel=&quot;stylesheet&quot; href=&quot;/static/assets/plugins/dropzone/min/dropzone.min.css&quot; /&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;/static/assets/plugins/dropzone/min/basic.min.css&quot; /&gt; JS 部分 1&lt;script src=&quot;/static/assets/plugins/dropzone/min/dropzone.min.js&quot;&gt;&lt;/script&gt; 启用 Dropzone只需要一个 div 元素，用 JavaScript 代码启用即可 HTML 结构如下： 1&lt;div id=&quot;dropz&quot; class=&quot;dropzone&quot;&gt;&lt;/div&gt; JavaScript 启用代码如下： 12345678910var myDropzone = new Dropzone(&quot;#dropz&quot;, &#123; url: &quot;/upload&quot;, dictDefaultMessage: &apos;拖动文件至此或者点击上传&apos;, // 设置默认的提示语句 paramName: &quot;dropzFile&quot;, // 传到后台的参数名称 init: function () &#123; this.on(&quot;success&quot;, function (file, data) &#123; // 上传成功触发的事件 &#125;); &#125;&#125;); 其中 url 是必须的值，指明文件上传提交到哪个页面。其他的值都是可选的，如果使用默认值的话可以省略。 配置 Dropzone此插件的特色就在于非常灵活，提供了许多可选项、事件等。下面分类介绍常用的配置项。 功能选项 url：最重要的参数，指明了文件提交到哪个页面 method：默认为 post，如果需要，可以改为 put paramName：相当于 &lt;input&gt; 元素的 name 属性，默认为 file maxFilesize：最大文件大小，单位是 MB maxFiles：默认为 null，可以指定为一个数值，限制最多文件数量 addRemoveLinks：默认 false。如果设为 true，则会给文件添加一个删除链接 acceptedFiles：指明允许上传的文件类型，格式是逗号分隔的 MIME type 或者扩展名。例如：image/*, application/pdf, .psd, .obj uploadMultiple：指明是否允许 Dropzone 一次提交多个文件。默认为 false。如果设为 true，则相当于 HTML 表单添加 multiple 属性 headers：如果设定，则会作为额外的 header 信息发送到服务器。例如：{&quot;custom-header&quot;: &quot;value&quot;} init：一个函数，在 Dropzone 初始化的时候调用，可以用来添加自己的事件监听器 forceFallback：Fallback 是一种机制，当浏览器不支持此插件时，提供一个备选方案。默认为 false。如果设为 true，则强制 fallback fallback：一个函数，如果浏览器不支持此插件则调用 翻译选项 dictDefaultMessage：没有任何文件被添加的时候的提示文本 dictFallbackMessage：Fallback 情况下的提示文本 dictInvalidInputType：文件类型被拒绝时的提示文本 dictFileTooBig：文件大小过大时的提示文本 dictCancelUpload：取消上传链接的文本 dictCancelUploadConfirmation：取消上传确认信息的文本 dictRemoveFile：移除文件链接的文本 dictMaxFilesExceeded：超过最大文件数量的提示文本 常用事件以下事件接收 FILE 为第一个参数 addedfile：添加了一个文件时发生 removedfile：一个文件被移除时发生。你可以监听这个事件并手动从服务器删除这个文件 uploadprogress：上传时按一定间隔发生这个事件。第二个参数为一个整数，表示进度，从 0 到 100。第三个参数是一个整数，表示发送到服务器的字节数。当一个上传结束时，Dropzone 保证会把进度设为 100。注意：这个函数可能被以同一个进度调用多次 success：文件成功上传之后发生，第二个参数为服务器响应 complete：当文件上传成功或失败之后发生 canceled：当文件在上传时被取消的时候发生 maxfilesreached：当文件数量达到最大时发生 maxfilesexceeded：当文件数量超过限制时发生 以下事件接收一个 FILE LIST 作为第一个参数（仅当 UPLOADMULTIPLE 被设为 TRUE 时才会发生） successmultiple completemultiple cancelmultiple 特殊事件 totaluploadprogress：第一个参数为总上传进度，第二个参数为总字节数，第三个参数为总上传字节数。 使用案例123456789101112131415161718192021222324252627282930313233var myDropzone = new Dropzone(&quot;#dropz&quot;, &#123; url: &quot;/upload&quot;, // 文件提交地址 method: &quot;post&quot;, // 也可用put paramName: &quot;file&quot;, // 默认为file maxFiles: 1,// 一次性上传的文件数量上限 maxFilesize: 2, // 文件大小，单位：MB acceptedFiles: &quot;.jpg,.gif,.png,.jpeg&quot;, // 上传的类型 addRemoveLinks: true, parallelUploads: 1,// 一次上传的文件数量 //previewsContainer:&quot;#preview&quot;, // 上传图片的预览窗口 dictDefaultMessage: &apos;拖动文件至此或者点击上传&apos;, dictMaxFilesExceeded: &quot;您最多只能上传1个文件！&quot;, dictResponseError: &apos;文件上传失败!&apos;, dictInvalidFileType: &quot;文件类型只能是*.jpg,*.gif,*.png,*.jpeg。&quot;, dictFallbackMessage: &quot;浏览器不受支持&quot;, dictFileTooBig: &quot;文件过大上传文件最大支持.&quot;, dictRemoveLinks: &quot;删除&quot;, dictCancelUpload: &quot;取消&quot;, init: function () &#123; this.on(&quot;addedfile&quot;, function (file) &#123; // 上传文件时触发的事件 &#125;); this.on(&quot;success&quot;, function (file, data) &#123; // 上传成功触发的事件 &#125;); this.on(&quot;error&quot;, function (file, data) &#123; // 上传失败触发的事件 &#125;); this.on(&quot;removedfile&quot;, function (file) &#123; // 删除文件时触发的方法 &#125;); &#125;&#125;); 服务端支持前端工作做完后，后台需要提供文件上传支持，我们使用 Spring MVC 来接收上传的文件 POMSpring MVC 上传文件需要 commons-fileupload:commons-fileupload 依赖支持，pom.xml 文件如下： 12345&lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt;&lt;/dependency&gt; 配置 spring-mvc.xml需要 Spring 注入 multipartResolver 实例，spring-mvc.xml 增加如下配置： 1234&lt;!-- 上传文件拦截，设置最大上传文件大小 10M = 10*1024*1024(B) = 10485760 bytes --&gt;&lt;bean id=&quot;multipartResolver&quot; class=&quot;org.springframework.web.multipart.commons.CommonsMultipartResolver&quot;&gt; &lt;property name=&quot;maxUploadSize&quot; value=&quot;10485760&quot;/&gt;&lt;/bean&gt; 控制器关键代码以下为控制器中接收文件的关键代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package com.funtl.my.shop.web.admin.web.controller;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.ResponseBody;import org.springframework.web.multipart.MultipartFile;import javax.servlet.http.HttpServletRequest;import java.io.File;import java.io.IOException;import java.util.HashMap;import java.util.Map;import java.util.UUID;/** * 文件上传控制器 * &lt;p&gt;Title: UploadController&lt;/p&gt; * &lt;p&gt;Description: &lt;/p&gt; * * @author Lusifer * @version 1.0.0 * @date 2018/6/27 0:42 */@Controllerpublic class UploadController &#123; @ResponseBody @RequestMapping(value = "upload", method = RequestMethod.POST) public Map&lt;String, Object&gt; upload(MultipartFile dropzFile, HttpServletRequest request) &#123; Map&lt;String, Object&gt; result = new HashMap&lt;&gt;(); // 获取上传的原始文件名 String fileName = dropzFile.getOriginalFilename(); // 设置文件上传路径 String filePath = request.getSession().getServletContext().getRealPath("/static/upload"); // 获取文件后缀 String fileSuffix = fileName.substring(fileName.lastIndexOf("."), fileName.length()); // 判断并创建上传用的文件夹 File file = new File(filePath); if (!file.exists()) &#123; file.mkdir(); &#125; // 重新设置文件名为 UUID，以确保唯一 file = new File(filePath, UUID.randomUUID() + fileSuffix); try &#123; // 写入文件 dropzFile.transferTo(file); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; // 返回 JSON 数据，这里只带入了文件名 result.put("fileName", file.getName()); return result; &#125;&#125;]]></content>
      <categories>
        <category>组件</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java线程生命周期]]></title>
    <url>%2F2018%2F11%2F13%2F%E7%BA%BF%E7%A8%8B%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%2F</url>
    <content type="text"><![CDATA[Java线程生命周期线程是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并行多个线程，每条线程并行执行不同的任务。 在多核或多CPU，或支持Hyper-threading的CPU上使用多线程程序设计的好处是显而易见，即提高了程序的执行吞吐率。在单CPU单核的计算机上，使用多线程技术，也可以把进程中负责I/O处理、人机交互而常被阻塞的部分与密集计算的部分分开来执行，编写专门的workhorse线程执行密集计算，从而提高了程序的执行效率。 线程的基本状态在Thread类中存在着一个内部类Thread.State，它描述着Java中线程的六种状态 NEWA thread that has not yet started is in this state. RUNNABLEA thread executing in the Java virtual machine is in this state. BLOCKEDA thread that is blocked waiting for a monitor lock is in this state. WAITINGA thread that is waiting indefinitely for another thread to perform a particular action is in this state. TIMED_WAITINGA thread that is waiting for another thread to perform an action for up to a specified waiting time is in this state. TERMINATEDA thread that has exited is in this state. 线程在给定时间点只能处于一种状态。这些状态是虚拟机状态，不反映任何操作系统线程状态。]]></content>
  </entry>
  <entry>
    <title><![CDATA[常见的Content-Type]]></title>
    <url>%2F2018%2F11%2F13%2F%E5%B8%B8%E8%A7%81%E7%9A%84Content-Type%2F</url>
    <content type="text"><![CDATA[常见的Content-Type属性x-www-form-urlencoded最常见的 POST 上传数据方式，浏览器原生表单如果不设置 enctype 就会以此种方式提交数据，需要上传的数据会以 key=value 的格式进行编码，随后进行 url 转码。 1234POST http://www.example.com HTTP/1.1Content-Type: application/x-www-form-urlencoded;charset=utf-8title=test&amp;sub%5B%5D=1&amp;sub%5B%5D=2&amp;sub%5B%5D=3 在使用 Ajax 提交数据是，也是使用这种方式。 multipart/form-data进行文件上传时，必须将表单 enctype 设为此值。 12345678910111213POST http://www.example.com HTTP/1.1Content-Type: multipart/form-data; boundary=----WebKitFormBoundaryrGKCBY7qhFd3TrwA------WebKitFormBoundaryrGKCBY7qhFd3TrwAContent-Disposition: form-data; name="text"title------WebKitFormBoundaryrGKCBY7qhFd3TrwAContent-Disposition: form-data; name="file"; filename="chrome.png"Content-Type: image/pngPNG ... content of chrome.png ...------WebKitFormBoundaryrGKCBY7qhFd3TrwA-- application/json用于传递 JSON 数据，表名传递的数据是序列化后的 JSON 字符串 1234POST http://www.example.com HTTP/1.1Content-Type: application/json;charset=utf-8&#123;"title":"test","sub":[1,2,3]&#125; text/xml作为 XML-RPC 传输的协议，用于 XML 远程过程调用 123456789101112POST http://www.example.com HTTP/1.1Content-Type: text/xml&lt;?xml version="1.0"?&gt;&lt;methodCall&gt; &lt;methodName&gt;examples.getStateName&lt;/methodName&gt; &lt;params&gt; &lt;param&gt; &lt;value&gt;&lt;i4&gt;41&lt;/i4&gt;&lt;/value&gt; &lt;/param&gt; &lt;/params&gt;&lt;/methodCall&gt;]]></content>
  </entry>
  <entry>
    <title><![CDATA[MyBatis]]></title>
    <url>%2F2018%2F11%2F09%2Fmybatis%2F</url>
    <content type="text"><![CDATA[参考[MyBatis-3-User-Guide-Simplified-Chinese.pdf]1. 入门 什么是MyBatis MyBatis基本配置：config, mapper 2. 列名与参数不一致 SQL方式：别名 MyBatis方式：ResultMap 强制标签顺序 3. #和$的区别 # 预编译 自动转义 防止SQL注入 eg. name -&gt; ‘name’ 用于赋值 使用参数名取值 eg. #{name} $ 拼接字符串 用于传递表名，ORDER BY，GROUP BY 使用value或属性取值 eg. ${value} 4. 多参传递 索引 eg. #{0} 注解 eg. @Param(value = “fieldName”) Map 5. 获取数据库生成ID Mapper配置 &lt;insert useGeneratedKeys=&quot;true&quot; keyProperty=&quot;id&quot;/&gt; Config配置 &lt;setting name=&quot;useGeneratedKeys&quot; value=&quot;true&quot;/&gt; 数据库不支持自动生成类型 &lt;selectKey keyProperty=&quot;id&quot; resultType=&quot;int&quot; order=&quot;AFTER&quot;/&gt; 6. 动态SQL &lt;if test=&quot;value != null and value != &#39;&#39;&quot;/&gt; choose when otherwise where set trim sql 7. MyBatis Generator12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970&lt;!-- generatorConfig.xml --&gt;&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC "-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN" "http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd"&gt;&lt;generatorConfiguration&gt; &lt;context id="testTables" targetRuntime="MyBatis3"&gt; &lt;!--序列化model--&gt; &lt;!--&lt;plugin type="org.mybatis.generator.plugins.SerializablePlugin"/&gt;--&gt; &lt;commentGenerator&gt; &lt;!--是否去除自动生成的注释 true：是 false：否--&gt; &lt;property name="suppressAllComments" value="true"/&gt; &lt;/commentGenerator&gt; &lt;!--数据库连接信息--&gt; &lt;jdbcConnection driverClass="com.mysql.jdbc.Driver" connectionURL="jdbc:mysql://localhost:3306/world" userId="root" password="toor"/&gt; &lt;!--&lt;jdbcConnection driverClass="oracle.jdbc.OracleDriver" --&gt; &lt;!--connectionURL="jdbc:oracle:thin:@localhost:1521:DB_NAME" --&gt; &lt;!--userId="scott" --&gt; &lt;!--password="tiger"/&gt;--&gt; &lt;!-- 默认false，把JDBC DECIMAL 和 NUMERIC 类型解析为 Integer，为 true时把JDBC DECIMAL 和 NUMERIC 类型解析为java.math.BigDecimal --&gt; &lt;javaTypeResolver&gt; &lt;property name="forceBigDecimals" value="false"/&gt; &lt;/javaTypeResolver&gt; &lt;!-- targetProject:生成PO类的位置 --&gt; &lt;javaModelGenerator targetPackage="name.mybatis.pojo" targetProject=".\src"&gt; &lt;!-- enableSubPackages:是否让schema作为包的后缀 --&gt; &lt;property name="enableSubPackages" value="false"/&gt; &lt;!-- 从数据库返回的值被清理前后的空格 --&gt; &lt;property name="trimStrings" value="true"/&gt; &lt;/javaModelGenerator&gt; &lt;!-- targetProject:mapper映射文件生成的位置 --&gt; &lt;sqlMapGenerator targetPackage="name.mybatis.pojo" targetProject=".\src"&gt; &lt;!-- enableSubPackages:是否让schema作为包的后缀 --&gt; &lt;property name="enableSubPackages" value="false"/&gt; &lt;/sqlMapGenerator&gt; &lt;!-- targetPackage：mapper接口生成的位置 --&gt; &lt;javaClientGenerator type="XMLMAPPER" targetPackage="name.mybatis.mapper" targetProject=".\src"&gt; &lt;!-- enableSubPackages:是否让schema作为包的后缀 --&gt; &lt;property name="enableSubPackages" value="false"/&gt; &lt;/javaClientGenerator&gt; &lt;!-- 指定数据库表 --&gt; &lt;table tableName="city" domainObjectName="City"/&gt; &lt;table tableName="country" domainObjectName="Country"/&gt; &lt;table tableName="countrylanguage" domainObjectName="CountryLanguage"/&gt; &lt;!--&lt;table schema="DB2ADMIN" tableName="ALLTYPES" domainObjectName="Customer"&gt;--&gt; &lt;!--&lt;property name="useActualColumnNames" value="true"/&gt;--&gt; &lt;!--&lt;generatedKey column="ID" sqlStatement="DB2" identity="true"/&gt;--&gt; &lt;!--&lt;columnOverride column="DATE_FIELD" property="startDate"/&gt;--&gt; &lt;!--&lt;ignoreColumn column="FRED"/&gt;--&gt; &lt;!--&lt;columnOverride column="LONG_VARCHAR_FIELD" jdbcType="VARCHAR"/&gt;--&gt; &lt;!--&lt;/table&gt;--&gt; &lt;!-- 有些表的字段需要指定java类型 &lt;table schema="" tableName=""&gt; &lt;columnOverride column="" javaType="" /&gt; &lt;/table&gt; --&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt; 123456789101112131415161718&lt;!-- pom.xml --&gt;&lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.5&lt;/version&gt; &lt;configuration&gt; &lt;configurationFile&gt;$&#123;basedir&#125;/src/main/resources/generatorConfig.xml&lt;/configurationFile&gt; &lt;overwrite&gt;false&lt;/overwrite&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;/configuration&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;$&#123;mysql.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/plugin&gt; 8. 缓存 默认开启局部session缓存 映射语句文件中的所有insert，update和delete语句会刷新缓存 开启二级缓存（表级缓存）在mapper设置&lt;cache/&gt;实体必须实现Serializable 9. 嵌套查询 多级单表查询 &lt;association select=&quot;&quot;/&gt; &lt;collection select=&quot;&quot;/&gt; 关联查询 10. 延迟加载 参考MyBatis配置&lt;settings/&gt; 11. TK MyBatis插件 12345&lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper&lt;/artifactId&gt; &lt;version&gt;4.0.4&lt;/version&gt;&lt;/dependency&gt; 12345678910111213141516171819202122&lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis-generator-core.version&#125;&lt;/version&gt; &lt;configuration&gt; &lt;configurationFile&gt;$&#123;basedir&#125;/src/main/resources/generator/generatorConfig.xml&lt;/configurationFile&gt; &lt;overwrite&gt;false&lt;/overwrite&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;/configuration&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;$&#123;mysql-connector-java.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper&lt;/artifactId&gt; &lt;version&gt;$&#123;mapper.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/plugin&gt; 1234567891011121314151617181920&lt;!--使用 Configuration 方式进行配置--&gt;&lt;bean id="mybatisConfig" class="tk.mybatis.mapper.session.Configuration"&gt; &lt;!-- 配置通用 Mapper，有三种属性注入方式 --&gt; &lt;property name="mapperProperties"&gt; &lt;value&gt; notEmpty=true &lt;/value&gt; &lt;/property&gt;&lt;/bean&gt;&lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;property name="configuration" ref="mybatisConfig"/&gt;&lt;/bean&gt;&lt;!-- 不需要考虑下面这个，注意这里是 org 的 --&gt;&lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;property name="basePackage" value="tk.mybatis.mapper.configuration"/&gt; &lt;property name="sqlSessionFactoryBeanName" value="sqlSessionFactory"/&gt;&lt;/bean&gt; 最小侵入式配置 1234public interface MyMapper&lt;T&gt; extends Mapper&lt;T&gt;, MySqlMapper&lt;T&gt; &#123; //TODO //FIXME 特别注意，该接口不能被扫描到，否则会出错&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package top.shieh.my.shop.commons.util;import org.mybatis.generator.api.IntrospectedColumn;import org.mybatis.generator.api.IntrospectedTable;import org.mybatis.generator.api.PluginAdapter;import org.mybatis.generator.api.dom.java.FullyQualifiedJavaType;import org.mybatis.generator.api.dom.java.Method;import org.mybatis.generator.api.dom.java.TopLevelClass;import java.util.List;public class LombokPlugin extends PluginAdapter &#123; private FullyQualifiedJavaType dataAnnotation = new FullyQualifiedJavaType("lombok.Data"); @Override public boolean validate(List&lt;String&gt; warnings) &#123; return true; &#125; @Override public boolean modelBaseRecordClassGenerated(TopLevelClass topLevelClass, IntrospectedTable introspectedTable) &#123; this.addDataAnnotation(topLevelClass); return true; &#125; @Override public boolean modelPrimaryKeyClassGenerated(TopLevelClass topLevelClass, IntrospectedTable introspectedTable) &#123; this.addDataAnnotation(topLevelClass); return true; &#125; @Override public boolean modelRecordWithBLOBsClassGenerated(TopLevelClass topLevelClass, IntrospectedTable introspectedTable) &#123; this.addDataAnnotation(topLevelClass); return true; &#125; @Override public boolean modelGetterMethodGenerated(Method method, TopLevelClass topLevelClass, IntrospectedColumn introspectedColumn, IntrospectedTable introspectedTable, ModelClassType modelClassType) &#123; return false; &#125; @Override public boolean modelSetterMethodGenerated(Method method, TopLevelClass topLevelClass, IntrospectedColumn introspectedColumn, IntrospectedTable introspectedTable, ModelClassType modelClassType) &#123; return false; &#125; private void addDataAnnotation(TopLevelClass topLevelClass) &#123; topLevelClass.addImportedType(this.dataAnnotation); topLevelClass.addAnnotation("@Data"); &#125;&#125; 将 org.mybatis.spring.mapper.MapperScannerConfigurer 改为 tk.mybatis.spring.mapper.MapperScannerConfigurer]]></content>
  </entry>
  <entry>
    <title><![CDATA[Druid 介绍及配置]]></title>
    <url>%2F2018%2F11%2F06%2FDruid%E4%BB%8B%E7%BB%8D%E5%8F%8A%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Druid 介绍及配置 Druid是什么？ Druid是Java语言中最好的数据库连接池。Druid能够提供强大的监控和扩展功能。 在哪里下载druid 正式版本下载： maven中央仓库: http://central.maven.org/maven2/com/alibaba/druid/ 怎么获取Druid的源码 Druid是一个开源项目，源码托管在github上，源代码仓库地址是 https://github.com/alibaba/druid。同时每次Druid发布正式版本和快照的时候，都会把源码打包，你可以从上面的下载地址中找到相关版本的源码 怎么配置maven Druid 0.1.18 之后版本都发布到maven中央仓库中，所以你只需要在项目的pom.xml中加上dependency就可以了。例如： 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;$&#123;druid-version&#125;&lt;/version&gt; &lt;/dependency&gt; 也可以选择 Maven仓库查找公共的仓库地址:http://www.mvnrepository.com/artifact/com.alibaba/druid 怎么打开Druid的监控统计功能 Druid的监控统计功能是通过filter-chain扩展实现，如果你要打开监控统计功能，配置StatFilter，具体看这里：https://github.com/alibaba/druid/wiki/%E9%85%8D%E7%BD%AE_StatFilter 怎样使用Druid的内置监控页面 内置监控页面是一个Servlet，具体配置看这里：https://github.com/alibaba/druid/wiki/%E9%85%8D%E7%BD%AE_StatViewServlet%E9%85%8D%E7%BD%AE 内置监控中的Web和Spring关联监控怎么配置？ Web关联监控配置 https://github.com/alibaba/druid/wiki/%E9%85%8D%E7%BD%AE_%E9%85%8D%E7%BD%AEWebStatFilter Spring关联监控配置 https://github.com/alibaba/druid/wiki/%E9%85%8D%E7%BD%AE_Druid%E5%92%8CSpring%E5%85%B3%E8%81%94%E7%9B%91%E6%8E%A7%E9%85%8D%E7%BD%AE 怎么配置防御SQL注入攻击 Druid提供了WallFilter，它是基于SQL语义分析来实现防御SQL注入攻击的。具体配置看这里：https://github.com/alibaba/druid/wiki/%E9%85%8D%E7%BD%AE-wallfilter Druid有没有参考配置 不同的业务场景需求不同，你可以使用我们的参考配置，但建议你仔细阅读相关文档，了解清楚之后做定制配置。https://github.com/alibaba/druid/wiki/%E9%85%8D%E7%BD%AE_DruidDataSource%E5%8F%82%E8%80%83%E9%85%8D%E7%BD%AE 我想日志记录JDBC执行的SQL，如何配置Druid提供了Log4jFilter、CommonsLogFilter和Slf4jFilter，具体配置看这里https://github.com/alibaba/druid/wiki/%E9%85%8D%E7%BD%AE_LogFilter 我的程序可能产生连接泄漏了，有什么办法？Druid提供了多种监测连接泄漏的手段，具体看这里：https://github.com/alibaba/druid/wiki/%E8%BF%9E%E6%8E%A5%E6%B3%84%E6%BC%8F%E7%9B%91%E6%B5%8B 在Druid中使用PSCache会有内存占用过大问题么？连接Oracle数据库，打开PSCache，在其他的数据库连接池都会存在内存占用过多的问题，Druid是唯一解决这个问题的连接池。具体看这里：https://github.com/alibaba/druid/wiki/Oracle%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8BPreparedStatementCache%E5%86%85%E5%AD%98%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88 有没有和其他数据库连接池的对比？各种数据库连接池对比https://github.com/alibaba/druid/wiki/%E5%90%84%E7%A7%8D%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E5%AF%B9%E6%AF%94 从其他连接池迁移要注意什么？不同连接池的参数参照对比： http://code.alibabatech.com/wiki/pages/viewpage.action?pageId=6947005DBCP迁移 https://github.com/alibaba/druid/wiki/DBCP%E8%BF%81%E7%A7%BB Druid中有没有类似Jboss DataSource中的ExceptionSorterExceptionSorter是JBoss DataSource中的优秀特性，Druid也有一样功能的ExceptionSorter，但不用手动配置，自动识别生效的。具体看这里：https://github.com/alibaba/druid/wiki/ExceptionSorter_cn Druid中的maxIdle为什么是没用的？maxIdle是Druid为了方便DBCP用户迁移而增加的，maxIdle是一个混乱的概念。连接池只应该有maxPoolSize和minPoolSize，druid只保留了maxActive和minIdle，分别相当于maxPoolSize和minPoolSize。 我的应用配置的是JNDI数据源，可以用DruidDataSource么？DruidDataSource支持JNDI配置，具体看这里：https://github.com/alibaba/druid/wiki/%E9%85%8D%E7%BD%AE_JNDI_Tomcat具体实现的类是这个：com.alibaba.druid.pool.DruidDataSourceFactory，你可以阅读代码加深理解。 我的应用已使用DBCP，是代码中写死的，怎样更换为Druid？可以的，Druid提供了一个中完全平滑迁移DBCP的办法。 1) 从http://repo1.maven.org/maven2/com/alibaba/druid/druid-wrapper/ 下载druid-wrapper-xxx.jar2) 加入druid-xxx.jar3) 从你的WEB-INF/lib/中删除dbcp-xxx.jar4) 按需要加上配置，比如JVM启动参数加上-Ddruid.filters=stat，动态配置druid的filters这种用法，使得可以在一些非自己开发的应用中使用Druid，例如在sonar中部署druid，sonar是一个使用jruby开发的web应用，写死了DBCP，只能够通过这种方法来更换。 我想试用快照版本，怎么获取？直接获取快照版本的地址是：http://code.alibabatech.com/mvn/snapshots/com/alibaba/druid/ ，使用快照版本建议加入我们QQ群 92748305，遇到问题直接反馈给我们。 有一些SQL执行很慢，我希望日志记录下来，怎么设置？在StatFilter配置中有慢SQL执行日志记录，看这里https://github.com/alibaba/druid/wiki/%E9%85%8D%E7%BD%AE_StatFilter 我希望加密我的数据库密码怎么办？运维和DBA都不希望把密码明文直接写在配置文件中，Druid提供了数据库秘密加密的功能。具体看这里：https://github.com/alibaba/druid/wiki/%E4%BD%BF%E7%94%A8ConfigFilter 如何参与Druid的开发Druid是一个通过github开源的项目，github的特性，使得你很容易参与其中。这里有详细说明https://github.com/alibaba/druid/wiki/%E5%A6%82%E4%BD%95%E5%8F%82%E4%B8%8E Druid的发布周期是怎样？Druid是一个活跃的项目，长期维护。每个月有一个发布窗口，除非遇到重大bug和非常紧急的需求，否则都是每个月最多发布一次。如果没有足够多的需求，发布窗口就不会被使用。 如果DruidDataSource在init的时候失败了，不再使用，是否需要close是的，如果DruidDataSource不再使用，必须调用close来释放资源，释放的资源包括关闭Create和Destory线程。 DruidDataSource支持哪些数据库？理论上说，支持所有有jdbc驱动的数据库。实际测试过的有 数据库 支持状态mysql 支持，大规模使用oracle 支持，大规模使用sqlserver 支持postgres 支持db2 支持h2 支持derby 支持sqlite 支持sybase 支持 Oracle下jdbc executeBatch时，更新行数计算不正确使用jdbc的executeBatch 方法，如果数据库为oracle，则无论是否成功更新到数据，返回值都是-2，而不是真正被sql更新到的记录数，这是Oracle JDBC Driver的问题，Druid不作特殊处理。 Druid如何自动根据URL自动识别DriverClass的Druid是根据url前缀来识别DriverClass的，这样使得配置更方便简洁。 前缀 DriverCLass 描述信息jdbc:odps com.aliyun.odps.jdbc.OdpsDriverjdbc:derby org.apache.derby.jdbc.EmbeddedDriverjdbc:mysql com.mysql.jdbc.Driverjdbc:oracle oracle.jdbc.driver.OracleDriverjdbc:microsoft com.microsoft.jdbc.sqlserver.SQLServerDriverjdbc:sybase:Tds com.sybase.jdbc2.jdbc.SybDriverjdbc:jtds net.sourceforge.jtds.jdbc.Driverjdbc:postgresql org.postgresql.Driverjdbc:fake com.alibaba.druid.mock.MockDriverjdbc:mock com.alibaba.druid.mock.MockDriverjdbc:hsqldb org.hsqldb.jdbcDriverjdbc:db2 COM.ibm.db2.jdbc.app.DB2Driver DB2的JDBC Driver十分混乱，这个匹配不一定对jdbc:sqlite org.sqlite.JDBCjdbc:ingres com.ingres.jdbc.IngresDriverjdbc:h2 org.h2.Driverjdbc:mckoi com.mckoi.JDBCDriverjdbc:cloudscape COM.cloudscape.core.JDBCDriverjdbc:informix-sqli com.informix.jdbc.IfxDriverjdbc:timesten com.timesten.jdbc.TimesTenDriverjdbc:as400 com.ibm.as400.access.AS400JDBCDriverjdbc:sapdb com.sap.dbtech.jdbc.DriverSapDBjdbc:JSQLConnect com.jnetdirect.jsql.JSQLDriverjdbc:JTurbo com.newatlanta.jturbo.driver.Driverjdbc:firebirdsql org.firebirdsql.jdbc.FBDriverjdbc:interbase interbase.interclient.Driverjdbc:pointbase com.pointbase.jdbc.jdbcUniversalDriverjdbc:edbc ca.edbc.jdbc.EdbcDriverjdbc:mimer:multi1 com.mimer.jdbc.Driver 如何保存监控记录https://github.com/alibaba/druid/wiki/%E6%80%8E%E4%B9%88%E4%BF%9D%E5%AD%98Druid%E7%9A%84%E7%9B%91%E6%8E%A7%E8%AE%B0%E5%BD%95 我想Log输出SQL执行的信息怎么办？https://github.com/alibaba/druid/wiki/%E9%85%8D%E7%BD%AE_LogFilter 如何配置Druid内置的log实现https://github.com/alibaba/druid/wiki/%E9%85%8D%E7%BD%AEdruid%E5%86%85%E7%BD%AE%E7%9A%84log%E5%AE%9E%E7%8E%B0 附：示例项目：https://github.com/windwant/spring-dubbo-service.githttps://github.com/windwant/spring-boot-service.git]]></content>
      <categories>
        <category>JDBC</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[IDEA错误]]></title>
    <url>%2F2018%2F11%2F06%2Fidea%E9%94%99%E8%AF%AF%2F</url>
    <content type="text"><![CDATA[1. Cannot start compilation: the output path is not specified for module “XXX”. Specify the output path in Configure Project.未定义编译路径，进入 Project Structure(Ctrl + Shift + Alt + S) -&gt; Project Settrings -&gt; Modules -&gt; 左侧选中选中 Module ，点击 Paths 在 Compiler output 中设置 Use module compile output path]]></content>
      <categories>
        <category>IDEA</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[整数包装类值比较问题]]></title>
    <url>%2F2018%2F10%2F31%2F%E6%95%B4%E6%95%B0%E5%8C%85%E8%A3%85%E7%B1%BB%E5%80%BC%E6%AF%94%E8%BE%83%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[对于Integer、Short、Byte、Character、Long 这些包装类，都有一个常量池，常量池的范围是-128~127之间。如果定义的包装类的值在这个范围内，则会直接返回内部缓存池中已经存在的对象的引用，而对于浮点型Float和Double这样的包装类，没有常量池机制，不管传入的值是多少，都会new一个新的对象。]]></content>
  </entry>
  <entry>
    <title><![CDATA[ifream高度问题]]></title>
    <url>%2F2018%2F10%2F31%2Fifream%E9%AB%98%E5%BA%A6%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[Add this to your &lt;head&gt; section: 12345&lt;script&gt; function resizeIframe(obj) &#123; obj.style.height = obj.contentWindow.document.body.scrollHeight + 'px'; &#125;&lt;/script&gt; And change your iframe to this: 1&lt;iframe src="..." frameborder="0" scrolling="no" onload="resizeIframe(this)" /&gt; As found on sitepoint discussion.]]></content>
      <categories>
        <category>前端</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[自定义注解]]></title>
    <url>%2F2018%2F10%2F25%2F%E8%87%AA%E5%AE%9A%E4%B9%89%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[自定义注解mate-annotation元注解是提供给注解的注解。Java5.0定义了4个标准的 meta-annotation 类型，它们被用来提供对其它 annotation 类型作说明。Java5.0 定义的元注解： @Target @Retention @Documented @Inherited @Target@Target 说明了Annotation所修饰的对象范围： Annotation 可被用于 packages、types（类、接口、枚举、Annotation类型）、类型成员（方法、构造方法、成员变量、枚举值）、方法参数和本地变量（如循环变量、catch参数）。在 Annotation 类型的声明中使用了 target 可更加明晰其修饰的目标。 取值定义在 ElementType 枚举中： ElementType.CONSTRUCTOR: 用于描述构造器 ElementType.FIELD: 用于描述域 ElementType.LOCAL_VARIABLE: 用于描述局部变量 ElementType.METHOD: 用于描述方法 ElementType.PACKAGE: 用于描述包 ElementType.PARAMETER: 用于描述参数 ElementType.TYPE: 用于描述类、接口(包括注解类型) 或 enum 声明 @Retention@Retention 定义了该 Annotation 被保留的时间长短：某些 Annotation 仅出现在源代码中，而被编译器丢弃；而另一些却被编译在 class 文件中；编译在 class 文件中的 Annotation 可能会被虚拟机忽略，而另一些在 class 被装载时将被读取（请注意并不影响 class 的执行，因为 Annotation 与 class 在使用上是被分离的）。使用这个 meta-Annotation 可以对 Annotation 的“生命周期”限制。 取值定义在 RetentionPoicy 枚举中： RetentionPoicy.SOURCE: 在源文件中有效 RetentionPoicy.CLASS: 在class文件中有效 RetentionPoicy.RUNTIME: 在运行时有效 @Documented@Documented 用于描述其它类型的 annotation 应该被作为被标注的程序成员的公共API，因此可以被例如 javadoc 此类的工具文档化。@Documented 是一个标记注解，没有成员。 @Inherited@Inherited 元注解是一个标记注解，@Inherited表示了被标注的 annotation 是可以被继承的。如果一个使用了 @Inherited 修饰的 annotation 类型被用于一个 class，则这个 annotation 将被用于该 class 的子类。当使用反射获取该某个类的子类 annotation 时也会获取到父类存在有 @inherited 声明的 annotation 。]]></content>
  </entry>
  <entry>
    <title><![CDATA[字节码工具javap]]></title>
    <url>%2F2018%2F10%2F25%2F%E5%AD%97%E8%8A%82%E7%A0%81%E5%B7%A5%E5%85%B7javap%2F</url>
    <content type="text"><![CDATA[javap命令详解javap是JDK自带的反汇编器，可以查看java编译器为我们生成的字节码。通过它，可以对照源代码和字节码，从而了解很多编译器内部的工作。可以在命令行窗口先用javap -help看下javap工具支持的选项：C:>javap -help 12345678910111213141516171819202122232425262728293031C:\&gt;javap -helpUsage: javap &lt;options&gt; &lt;classes&gt;...where options include: -c 输出类中各方法的未解析的代码，即构成java字节码的指令 -classpath &lt;pathlist&gt; 指定javap用来查找类的路径。目录用：分隔 -extdirs &lt;dirs&gt; 覆盖搜索安装方式扩展的位置，扩展的缺省位置为jre/lib/ext -help 输出帮助信息 -J&lt;flag&gt; 直接将flag传给运行时系统 -l 输出行及局部变量表 -public 只显示public类及成员 -protected 只显示protected和public类及成员。 -package 只显示包、protected和public类及成员，，这是缺省设置 -private 显示所有的类和成员 -s 输出内部类型签名 -bootclasspath &lt;pathlist&gt; 指定加载自举类所用的路径，如jre/lib/rt.jar或i18n.jar -verbose 打印堆栈大小、各方法的locals及args参数，以及class文件的编译版本 平时一般用-c选项用得比较多，该命令用于列出每个方法所执行的JVM指令，并显示每个方法的字节码的实际作用。可以写个HelloWorld的程序来测试一下该命令。 123456789public class HelloWorld &#123; public static void main(String[] args)&#123; System.out.println("Hello World!"); &#125;&#125; 在将该java类编译生成HelloWorld.class文件后，即可通过javap进行具体的反编译分析。如：123456789101112131415$ javap -cHelloWorldCompiled from "HelloWorld.java"public class HelloWorld extends java.lang.Object&#123;public HelloWorld(); Code: 0: aload_0 1: invokespecial #1; //Method java/lang/Object."&lt;init&gt;":()V 4: return 12345678910111213public static void main(java.lang.String[]); Code: 0: getstatic #2; //Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #3; //String Hello World! 5: invokevirtual #4; //Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return&#125; 为了能够更清晰的了解javap反编译生成的字节码，下面来分析main方法中的指令,vcb用于转换Java语言中的代码行System.out.println(“HelloWorld!”); 0: getstatic #2; //Fieldjava/lang/System.out:Ljava/io/PrintStream; 最初始的整数表示方法中指令的偏移量，因此第一个指令是从0开始的。它表示的是从java.lang.system对象的out字段中检索PrintStream对象，getstatic指令即是将该静态域压缩并放到操作数栈中。按下来的指令则是引用一个地址，在当前情况下，指的是“#2;//Field java/lang/System.out:Ljava/io/PrintStream;”。在此你将会发现该域信息并没有直接嵌入进来。相反它是通过类似java类中的其它常量一样，该域信息被存储在一个共享池中。采用该常量池的方式能够减小字节码指令的长度。这也就是为什么指令中仅仅保存常量池的地址索引，而非所有的信息。在本示例中，域信息被存放在常量池中标识有#2的位置。 3: ldc #3; //String Hello World! 其实分析完第一条指令后，将非常容易的猜测到第二条指令的具体含义了。ldc(load constant)指令用于将HelloWorld！字符串压入至栈中。 5: invokevirtual #4; //Method java/io/PrintStream.println:(Ljava/lang/String;)V 该指令将调用println方法，它将从操作栈中弹出两个参数。千成别忘记了象println这样的实例方法其实是包含了两个参数的，一个是字符串，另一个是隐式的this索引。 上面的minor version: 0和majorversion: 49就是编译Worke.class时使用的jdk编译版本号。 但是它并不是我们所熟悉的jdk版本号（比如jdk1.5）。 不过我们可以把从 JDK 1.1 到 JDK 1.7 编译器编译出的 class 的默认minor.major version 汇总下就知道对应关系了。 JDK 编译器版本 target 参数 十六进制 minor.major 十进制 minor.major jdk1.1.8 不能带 target 参数 00 03 00 2D 45.3 jdk1.2.2 不带(默认为 -target 1.1) 00 03 00 2D 45.3 jdk1.2.2 -target 1.2 00 00 00 2E 46.0 jdk1.3.1_19 不带(默认为 -target 1.1) 00 03 00 2D 45.3 jdk1.3.1_19 -target 1.3 00 00 00 2F 47.0 j2sdk1.4.2_10 不带(默认为 -target 1.2) 00 00 00 2E 46.0 j2sdk1.4.2_10 -target 1.4 00 00 00 30 48.0 jdk1.5.0_11 不带(默认为 -target 1.5) 00 00 00 31 49.0 jdk1.5.0_11 -target 1.4 -source 1.4 00 00 00 30 48.0 jdk1.6.0_01 不带(默认为 -target 1.6) 00 00 00 32 50.0 jdk1.6.0_01 -target 1.5 00 00 00 31 49.0 jdk1.6.0_01 -target 1.4 -source 1.4 00 00 00 30 48.0 jdk1.7.0 不带(默认为 -target 1.6) 00 00 00 32 50.0 jdk1.7.0 -target 1.7 00 00 00 33 51.0 jdk1.7.0 -target 1.4 -source 1.4 00 00 00 30 48.0 Apache Harmony 5.0M3 不带(默认为 -target 1.2) 00 00 00 2E 46.0 Apache Harmony 5.0M3 -target 1.4 00 00 00 30 48.0]]></content>
  </entry>
  <entry>
    <title><![CDATA[JDK内置工具]]></title>
    <url>%2F2018%2F10%2F25%2FJDK%E5%86%85%E7%BD%AE%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[JDK内置工具 javah命令(C Header and Stub File Generator) jps命令(Java Virtual Machine Process Status Tool) jstack命令(Java Stack Trace) jstat命令(Java Virtual Machine Statistics Monitoring Tool) jmap命令(Java Memory Map) jinfo命令(Java Configuration Info) jconsole命令(Java Monitoring and Management Console) jvisualvm命令(Java Virtual Machine Monitoring, Troubleshooting, and Profiling Tool) jhat命令(Java Heap Analyse Tool) Jdb命令(The Java Debugger) Jstatd命令(Java Statistics Monitoring Daemon) javah命令javah是用于根据JAVA本地方法，生成对应的c语言头文件及相应的stub文件的命令，使用比较简单，使用示例可以查看这篇文章：JNI简单示例,包括C语言实现及调用 jps命令1、介绍 用来查看基于HotSpot的JVM里面中，所有具有访问权限的Java进程的具体状态, 包括进程ID，进程启动的路径及启动参数等等，与unix上的ps类似，只不过jps是用来显示java进程，可以把jps理解为ps的一个子集。 使用jps时，如果没有指定hostid，它只会显示本地环境中所有的Java进程；如果指定了hostid，它就会显示指定hostid上面的java进程，不过这需要远程服务上开启了jstatd服务，可以参看前面的jstatd章节来启动jstad服务。 2、命令格式 1jps [ options ] [ hostid ] 3、常用参数说明 -q 忽略输出的类名、Jar名以及传递给main方法的参数，只输出pid。 -m 输出传递给main方法的参数，如果是内嵌的JVM则输出为null。 -l 输出应用程序主类的完整包名，或者是应用程序JAR文件的完整路径。 -v 输出传给JVM的参数。 -V 输出通过标记的文件传递给JVM的参数（.hotspotrc文件，或者是通过参数-XX:Flags=指定的文件）。 -J 用于传递jvm选项到由javac调用的java加载器中，例如，“-J-Xms48m”将把启动内存设置为48M，使用-J选项可以非常方便的向基于Java的开发的底层虚拟机应用程序传递参数。 4、服务器标识 hostid指定了目标的服务器，它的语法如下：1[protocol:][[//]hostname][:port][/servername] protocol - 如果protocol及hostname都没有指定，那表示的是与当前环境相关的本地协议，如果指定了hostname却没有指定protocol，那么protocol的默认就是rmi。 hostname - 服务器的IP或者名称，没有指定则表示本机。 port - 远程rmi的端口，如果没有指定则默认为1099。 Servername - 注册到RMI注册中心中的jstatd的名称。 5、使用示例 5.1、列出本地的Java进程 不带任何参数1234fenglibin@libin:~$ jps11644 Main1947 12843 Jps 带-v参数1234fenglibin@libin:~$ jps -v11644 Main -agentlib:jdwp=transport=dt_socket,suspend=y,address=localhost:43467 -Dfile.encoding=GBK1947 -Dosgi.requiredJavaVersion=1.5 -XX:MaxPermSize=256m -Xms40m -Xmx512m12858 Jps -Denv.class.path=/home/fenglibin/java6/lib/dt.jar:/home/fenglibin/java6/lib/tools.jar::/usr/bin/libtool:/usr/bin/autoconf:/usr/local/BerkeleyDB.4.8/lib -Dapplication.home=/home/fenglibin/java6 -Xms8m 带-l参数1234fenglibin@libin:~$ jps -l11644 com.alibaba.china.webww.core.Main12870 sun.tools.jps.Jps1947 5.2、列出远程的Java进程 在jstatd章节，我们有通过：1rmiregistry 2020&amp;jstatd -J-Djava.security.policy=all.policy -p 2020 -n AlternateJstatdServerName 启动了名为AlternateJstatdServerName的jstatd服务，那么我们此时就可以通过该服务列出其有权限访问的Java进程。123456fenglibin@libin:~$ jps 10.1.1.234:2020/AlternateJstatdServerName29556 Bootstrap28671 WSPreLauncher2602 RegistryImpl18272 Test2603 Jstatd jstack命令1、介绍jstack用于打印出给定的java进程ID或core file或远程调试服务的Java堆栈信息，如果是在64位机器上，需要指定选项”-J-d64”，Windows的jstack使用方式只支持以下的这种方式：1jstack [-l] pid 如果java程序崩溃生成core文件，jstack工具可以用来获得core文件的java stack和native stack的信息，从而可以轻松地知道java程序是如何崩溃和在程序何处发生问题。另外，jstack工具还可以附属到正在运行的java程序中，看到当时运行的java程序的java stack和native stack的信息, 如果现在运行的java程序呈现hung的状态，jstack是非常有用的。 2、命令格式123jstack [ option ] pidjstack [ option ] executable corejstack [ option ] [server-id@]remote-hostname-or-IP 3、常用参数说明1)、options： executable Java executable from which the core dump was produced.(可能是产生core dump的java可执行程序) core 将被打印信息的core dump文件 remote-hostname-or-IP 远程debug服务的主机名或ip server-id 唯一id,假如一台主机上多个远程debug服务 2）、基本参数： -F当’jstack [-l] pid’没有相应的时候强制打印栈信息 -l长列表. 打印关于锁的附加信息,例如属于java.util.concurrent的ownable synchronizers列表. -m打印java和native c/c++框架的所有栈信息. -h | -help打印帮助信息 pid 需要被打印配置信息的java进程id,可以用jps查询. jstat命令1、介绍Jstat用于监控基于HotSpot的JVM，对其堆的使用情况进行实时的命令行的统计，使用jstat我们可以对指定的JVM做如下监控： 类的加载及卸载情况 查看新生代、老生代及持久代的容量及使用情况 查看新生代、老生代及持久代的垃圾收集情况，包括垃圾回收的次数及垃圾回收所占用的时间 查看新生代中Eden区及Survior区中容量及分配情况等 jstat工具特别强大，它有众多的可选项，通过提供多种不同的监控维度，使我们可以从不同的维度来了解到当前JVM堆的使用情况。详细查看堆内各个部分的使用量，使用的时候必须加上待统计的Java进程号，可选的不同维度参数以及可选的统计频率参数。 它主要是用来显示GC及PermGen相关的信息，如果对GC不怎么了解，先看这篇文章：http://blog.csdn.net/fenglibing/archive/2011/04/13/6321453.aspx，否则其中即使你会使用jstat这个命令，你也看不懂它的输出。 2、语法1jstat [ generalOption | outputOptions vmid [interval[s|ms] [count]] ] generalOption - 单个的常用的命令行选项，如-help, -options, 或 -version。 outputOptions -一个或多个输出选项，由单个的statOption选项组成，可以和-t, -h, and -J等选项配合使用。 statOption：根据jstat统计的维度不同，可以使用如下表中的选项进行不同维度的统计，不同的操作系统支持的选项可能会不一样，可以通过-options选项，查看不同操作系统所支持选项，如： Option Displays… class 用于查看类加载情况的统计 compiler 用于查看HotSpot中即时编译器编译情况的统计 gc 用于查看JVM中堆的垃圾收集情况的统计 gccapacity 用于查看新生代、老生代及持久代的存储容量情况 gccause 用于查看垃圾收集的统计情况（这个和-gcutil选项一样），如果有发生垃圾收集，它还会显示最后一次及当前正在发生垃圾收集的原因。 gcnew 用于查看新生代垃圾收集的情况 gcnewcapacity 用于查看新生代的存储容量情况 gcold 用于查看老生代及持久代发生GC的情况 gcoldcapacity 用于查看老生代的容量 gcpermcapacity 用于查看持久代的容量 gcutil 用于查看新生代、老生代及持代垃圾收集的情况 printcompilation HotSpot编译方法的统计]]></content>
  </entry>
  <entry>
    <title><![CDATA[Java内省机制]]></title>
    <url>%2F2018%2F10%2F25%2FJava%E5%86%85%E7%9C%81%2F</url>
    <content type="text"><![CDATA[Java内省机制内省( Introspector ) 是 Java 语言对 JavaBean 类属性、事件的一种缺省处理方法。 JavaBean是一种特殊的类，主要用于传递数据信息，这种类中的方法主要用于访问私有的字段，且方法名符合某种命名规则。如果在两个模块之间传递信息，可以将信息封装进 JavaBean 中，这种对象称为“值对象”( Value Object )，或“ VO ”。方法比较少。这些信息储存在类的私有变量中，通过 setter/getter 获得。 Java JDK 中提供了一套 API 用来访问某个属性的 getter/setter 方法，这就是内省。 JDK内省类库PropertyDescriptor类PropertyDescriptor类表示 JavaBean 类通过存储器导出一个属性。主要方法： getPropertyType()，获得属性的 Class 对象; getReadMethod()，获得用于读取属性值的方法； getWriteMethod()，获得用于写入属性值的方法; hashCode()，获取对象的哈希值; setReadMethod(Method readMethod)，设置用于读取属性值的方法; setWriteMethod(Method writeMethod)，设置用于写入属性值的方法。 Introspector类将 JavaBean 中的属性封装起来进行操作。在程序把一个类当做 JavaBean 来看，就是调用 Introspector.getBeanInfo() 方法，得到的 BeanInfo 对象封装了把这个类当做 JavaBean 看的结果信息，即属性的信息。 BeanUtils工具包Apache开发了一套简单、易用的API来操作Bean的属性——BeanUtils工具包。 BeanUtils工具包 注意：应用的时候还需要一个logging包]]></content>
  </entry>
  <entry>
    <title><![CDATA[Java8内存模型]]></title>
    <url>%2F2018%2F10%2F25%2FJava8%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[Java8内存模型 控制参数 使用说明 -Xms 设置堆的最小空间大小 -Xmx 设置堆的最大空间大小 -XX:NewSize 设置新生代最小空间大小 -XX:MaxNewSize 设置新生代最大空间大小 -XX:PermSize 设置永久代最小空间大小 -XX:MaxPermSize 设置永久代最大空间大小 -Xss 设置每个线程的堆栈大小 HEAP：堆内存由JVM在程序启动时创建，用于存储对象。堆内存可以被任何线程访问，进一步分为三代Young Generation，Old＆PermGen（永久生成）。当对象被创建时，它首先进入Young代（尤其是Eden空间），当对象变老时，它会移动到Old / tenured Generation。在PermGen空间中，存储所有静态和实例变量名称 - 值对（对象的名称引用）。 Stack：使用程序创建的每个线程生成堆栈。它由线程关联。每个线程都有自己的堆栈。所有局部变量和函数调用都存储在堆栈中。它的生命取决于线程的生命，因为线程将存在，它也将存在，反之亦然。它也可以手动增加 PC寄存器：它也与其线程相关联。它基本上是正在执行的当前指令的地址。由于每个线程将要执行的一些方法集取决于PC寄存器。它对每个指令都有一些值，对于本机方法是未定义的。通常用于跟踪指令。 Method Area：它是像Heap这样的所有线程共享的内存。它是在Java Virtual Machine启动时创建的。它包含代码实际上是编译的代码，方法及其数据和字段。运行时常量池也是方法区域的一部分。它的内存默认由JVM分配，如果需要可以增加。运行时常量池是常量表的每个类表示。它包含在编译时定义的所有文字和将在运行时解决的引用。 Native方法堆栈本：机方法是用java以外的语言编写的方法。JVM实现无法加载本机方法，也无法依赖传统堆栈。它还与每个线程相关联。简而言之，它与堆栈相同，但它用于本机方法。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Shiro]]></title>
    <url>%2F2018%2F10%2F09%2Fshiro%2F</url>
    <content type="text"><![CDATA[参考Apache Shiro Reference Documentation1. QuickStartApache Shiro是一个具有许多功能的综合应用程序安全框架。 Shiro针对Shiro开发团队所称的“应用程序安全的四大基石” - 身份验证，授权，会话管理和加密： Authentication：有时也称为“登录”，这是证明用户是他们所说的人的行为。 Authorization：访问控制的过程，即确定“谁”可以访问“什么”。 Session Management：即使在非Web或EJB应用程序中，也可以管理特定于用户的会话。 Cryptography：使用加密算法保持数据安全，同时仍然易于使用。 在不同的应用程序环境中还有其他功能可以支持和强化这些问题，尤其是： Web支持：Shiro的Web支持API可帮助轻松保护Web应用程序。 缓存：缓存是Apache Shiro API中的第一层公民，可确保安全操作保持快速高效。 并发：Apache Shiro支持具有并发功能的多线程应用程序。 测试：存在测试支持以帮助您编写单元和集成测试，并确保您的代码按预期受到保护。 “运行方式”：允许用户假定其他用户的身份（如果允许）的功能，有时在管理方案中很有用。 “记住我”：记住用户在会话中的身份，这样他们只需要在强制要求时登录。 2.]]></content>
  </entry>
  <entry>
    <title><![CDATA[JNI简单示例]]></title>
    <url>%2F2018%2F09%2F04%2FJNI%2F</url>
    <content type="text"><![CDATA[JNI简单示例原贴地址JNI简单示例,包括C语言实现及调用 JNI（Java Native Interface）是Java本地方法调用接口，从Java1.1开始，Java Native Interface(JNI)标准就成为java平台的一部分，它允许Java代码和其他语言写的代码进行交互。JNI一开始是为了本地已编译语言，尤其是C和C++而设计的，但是它并不妨碍你使用其他语言，只要调用约定受支持就可以了。 Java中很多地方都使用到了JNI，如System.arrayCopy方法： 1public static native void arraycopy(Object array1, int start1, Object array2, int start2, int length); 那Java中为什么要使用JNI呢？这与Java产生的历史就有一定的关系了，Java刚开始被设计的时候就是为了跨平台，Java的字节码由JVM运行。Java跨平台是非常好的设计理念，这避免了因为换平台而不得不重新写一套代码的麻烦，可正是为了实现这样的特性，Java也失去了一些特性，如对操作系统底层的调用限制。JNI可以实现对操作系统底层的调用，JNI可以用来提高调用的速度，如我们上面提到的System.arrayCopy方法，它是直接和操作系统的内存进行交互，而省去了JVM和操作系统进行内存交换的步骤；JNI的另一个使用场景就是某些核心类库的实现可能需要跨包调用或者需要绕过其他Java安全性检查，如Java中的sun.misc.Unsaef实现。 下面我们用两个实例来说明，如何创建自己的DLL，以及如何通过Java去调用这些DLL。 示例一、不传参数的简单调用 这个示例很简单，没有输入参数也没有输出参数，只是通过Java调用JNI方法，并把JNI中输出的一句话给显示出来。如果是涉及到输入输出参数的本地方法调用，相对就会麻烦一点，因为Java中的参数和DLL中的参数类型是不一样的，这时就需要一个中间转换间，如SWIG（Simplified Wrapper and Interface Generator）简单包装及接口生成器，这个后面会有介绍。 1、Java的操作步骤 1）、首先准备一个具有本地方法的Java文件JNITest，输入内容如下： 1234567package test;public class JNITest &#123; /* * 建立一个无返回参数的方法，该方法只在DLL方法内打印一条语句。 */ public native void test();&#125; 2）、使用Javac编译该Java文件1javac test/JNITest.java 注：编译一定要在test包外操作，否则会报错。3）、使用Javah生成头文件1javah test.JNITest 注：也是要在test包外操作操作完成后，我们可以看到_头文件”test_JNITest.h”_，它的命令方式是以包名加类名的方式，其内容如下：12345678910111213141516171819/* DO NOT EDIT THIS FILE - it is machine generated */#include &lt;jni.h&gt;/* Header for class test_JNITest */#ifndef _Included_test_JNITest#define _Included_test_JNITest#ifdef __cplusplusextern "C" &#123;#endif/* * Class: test_JNITest * Method: test * Signature: ()I */JNIEXPORT jint JNICALL Java_test_JNITest_test (JNIEnv *, jobject);#ifdef __cplusplus&#125;#endif#endif 正如文件头部所说，不要对这个生成文件进行任何的修改一样，然后通过C实现该方法即可：1JNIEXPORT jint JNICALL Java_test_JNITest_test (JNIEnv *, jobject); 然后我们将实现后的C，编译成DLL，再将DLL放到操作系统的PATH中，如我是WINDOWS中，将其放到system32路径下即可，DLL的名称没有关系。4）、执行测试结果 建立一个测试类JNITestCaller1234567891011public class JNITestCaller &#123; static &#123; // 在系统路径中（如system32）加载名为JNITest.dll文件 System.loadLibrary("JNITest"); &#125; public static void main(String[] arg) &#123; JNITest jniTest = new JNITest(); jniTest.test(); &#125;&#125; 通过javac编译该Java类1javac test/JNITestCaller 然后执行它1java test.JNITestCaller 如果控制台打印出“=====888”字符串，则表示通过JNI调用DLL成功且执行成功，如果不成功则检查步骤是否有遗漏。 2、DLL编译的步骤 1）、安装VC6， VS太大了，我等也不常用，这个可以了； 2）、启动VC6，新建DLL工程，通过“File-&gt;New…-&gt;Dll工程”，名称就命名为JNITest吧，到时编译过后的DLL名称就是JNITest.dll，如果是其它的名称，在编译成DLL后需要改一下名称； 3）、新建C++ 选中新建工程JNITest，然后点击菜单中的“File-&gt;New…-&gt;C++ Source File”，文件的名称可以任意，在其中输入如下代码： 在其中输入如下如下代码：1234567891011121314#include &lt;jni.h&gt;#include &lt;stdlib.h&gt;#include &lt;test_JNITest.h&gt;#ifdef __cplusplusextern "C" &#123;#endif/*这个方法名称一定要和头文件的一模一样，不过头文件中的参数只有类型，没有名称，需要加成如下参数*/JNIEXPORT void JNICALL Java_test_JNITest_test(JNIEnv *jenv, jobject jobj) &#123; /*就打印这一条语句*/ printf("=====888");&#125;#ifdef __cplusplus&#125;#endif 4）、将%JAVA_HOME%/include/win32下面的jawt_md.h、jni_mh.h，以及%JAVA_HOME%/include/jni.h，这三个文件拷贝到%VS_HOME%/VC98/Include下面，生成的头文件test_JNITest.h也可以拷贝到那个目录，省去指定头文件的路径步骤；5）、点击C++的编译按钮（或者CTRL+F7），不报错则通过，则点击生成DLL文件的按钮（或者F7），到%VS_HOME%/MyProject/JNITest目录，将JNITest.dll文件拷贝到system32目录就可以了。 示例二、有输入输出参数的调用，需要借助工具SWIG（Simplified Wrapper and Interface Generator） Java中JNI的操作，最难的就是Java与Dll之间参数的传递与转换了，因为JAVA中的参数与C中的参数是不能够直接匹配的，如果我们手工去处理，还真的有点麻烦。这个时候我们可以通过SWIG这个工具来做参数的包装，它可以帮忙做传入传出参数之间的转换，我们现在上面的基础之上，将原来的void且不传参数的方法，改成传入两个字符串，返回的结果为这两个字符串的组合，如传入参数为”A”、”B”，则输出结果为”AB”，操作步骤如下： 1、Java中的操作 Java中需要将Native方法增加两个输入参数以及修改返回参数，这个Native方法的功能就是返回两个输入参数的拼接结果，如参数输入“A”和“B”，那要得到的结果是“AB”，修改后的包含Native方法的类的代码如下： 12345678package test;public class JNITest &#123; /* * 建立一个无返回参数的方法，该方法只在DLL方法内打印一条语句。 另外就是传参的处理要相对复杂点，后面介绍。 */ public native String test(String a, String b);&#125; 此时我们的测试代码也会有一点点小小的改变，增加传入参数以及获取返回结果，修改后的JNITestCaller代码如下： 1234567891011121314package test;public class JNITestCaller &#123; static &#123; // 在系统路径中（如system32）加载名为JNITest.dll文件 System.loadLibrary("JNITest"); &#125; public static void main(String[] arg) &#123; JNITest jniTest = new JNITest(); String a = "A", b = "B"; String result = jniTest.test(a, b); System.out.println("The execute result is:" + result); &#125;&#125; 如果我们按照上面的操作，并可以在最后得到输出结果“AB”，那么就表示我们的操作成功了。 2、DLL编译的步骤 1）、首先是下载SWIG，要包括WIN的那个版本，这个版本才有SWIG.EXE这个文件； 2）、然后设置SWIG当前路径到PATH中，因为执行SWIG命令的时候需要用到； 3）、编写”.i”文件如“I.i”，这个文件里面定义要生成的C方法是什么，这个方法就是要实现的方法，具体怎么写就需要看看SWIG的示例与帮助文档了，里面还是挺丰富的； 4）、执行命令“swig -java -c++ I.i”，会生成C语言包装、C++包装、两个JAVA文件，其中包括了声明本地native方法类，以及引用方法native方法的类，但是在实现类中没有实现MAIN方法以及通过System.loadLibary的方法加载DLL，这两个需要用户自己完成。 注：用户需要自己通过C或者是C++实现在”.i”文件中声明的方法，才可以成功编译，因为C及C++的包装文件中会引用这个方法，我们不需要修改包装文件，直接在另外一个C或者是C++文件中实现那个文件即可。 5）、调用和上面的一样，编译JAVA，执行JAVA，不过不用调用JAVAH生成H头文件了，因为由SWIG已经生成了对应的包装文件。 这个没有给出示例，因为SWIG生成的包装文件比较大，它其中做了字符的转换，有了上面的基础，再通过SWIG去实现，应该没有多大难度。 注：DLL的步骤，后面会补充完整。]]></content>
  </entry>
  <entry>
    <title><![CDATA[SQL_NOTIN与IN中NULL值问题]]></title>
    <url>%2F2018%2F07%2F17%2FSQL_NOTIN%E4%B8%8EIN%E4%B8%ADNULL%E5%80%BC%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[To state it simply, why does query A return a result but B doesn’t? 12A: select &apos;true&apos; where 3 in (1, 2, 3, null)B: select &apos;true&apos; where 3 not in (1, 2, null) This was on SQL Server 2005. I also found that calling set ansi_nulls off causes B to return a result. Query A is the same as:1select 'true' where 3 = 1 or 3 = 2 or 3 = 3 or 3 = null Since 3 = 3 is true, you get a result. Query B is the same as:1select 'true' where 3 &lt;&gt; 1 and 3 &lt;&gt; 2 and 3 &lt;&gt; null When ansi_nulls is on, 3 &lt;&gt; null is UNKNOWN, so the predicate evaluates to UNKNOWN, and you don’t get any rows. When ansi_nulls is off, 3 &lt;&gt; null is true, so the predicate evaluates to true, and you get a row.]]></content>
  </entry>
  <entry>
    <title><![CDATA[线程池]]></title>
    <url>%2F2018%2F07%2F10%2F%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[线程池 线程池是预先创建线程的一种技术。线程池在还没有任务到来之前，创建一定数量的线程，放入空闲队列中，然后对这些资源进行重复使用。减少频繁的创建和销毁对象。 jdk1.5版本以上提供了现成的线程池。 java里面线程池的顶级接口是Executor，是一个执行线程的工具。 线程池接口是ExecutorService。 java.util.concurrent：并发编程中很常用的实用工具类 Executor接口： 执行已提交的Runnable任务的对象。 ExecutorService接口： Executor提供了管理终止的方法，以及可以跟踪一个或多个异步任务执行状况而生成Future的方法。 Execute类： 此包中所定义的Executor、ExecutorService等的工厂和实用方法。 在Executors类里面提供了一些静态工厂，生成一些常用的线程池。 newSingleThreadExecutor：创建一个单线程的线程池。这个线程池只有一个线程在工作，也就是相当于单线程串行执行所有任务。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它。此线程保证所有任务的执行顺序按照任务的提交顺序执行。 newFixedThreadPool：创建固定大小的线程池。每次提交体格任务就创建一个线程。直到线程达到线程池的最大大小。线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。 newCachedThreadPool：创建一个可缓存的线程池。如果线程池的大小超过了处理任务所需要的线程，那么就会回收部分空闲（60秒不执行任务）的线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。此线程不会对线程池的大小做限制，线程池的大小完全依赖与操作系统（或者说JVM）能够创建的最大线程大小。 newScheduledThreadPool：创建一个无限大小的线程池。此线程池支持定时以及周期性执行任务的需求。]]></content>
  </entry>
  <entry>
    <title><![CDATA[单例设计模式优化]]></title>
    <url>%2F2018%2F07%2F10%2F%E5%8D%95%E4%BE%8B%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[单例设计模式优化 使用同步保证线程安全synchronized 使用volatile关键字 volatile提醒编译器它后面所定义的变量随时都有可能改变，因此编译后的程序每次需要存储或读取这个变量的时候，都会直接从变量地址中读取数据。如果没有volition关键字，则编译器可能优化读取和存储，可能暂时使用寄存器中的值，如果这个变量由别的程序更新了的话，将出现不一致的现象。 防止反射调用私有构造方法 让单例类序列化安全 12345678910111213141516171819202122232425/** * 单例模式 * 1. 多线程访问的安全问题 * 2. 加上volatile关键字保证变量的一致性 * 3. 防止反射调用私有构造方法 * 4. 让单例类可以被序列化 */public class Singleton implements Serializable &#123; private volatile static Singleton INSTANCE = null; private Singleton() &#123; if (INSTANCE != null) &#123; throw new RuntimeException("Singleton that has been instantiated."); &#125; &#125; public static Singleton getInstance() &#123; if (INSTANCE == null) &#123; synchronized (Singleton.class) &#123; if (INSTANCE == null) &#123; INSTANCE = new Singleton(); &#125; &#125; &#125; return INSTANCE; &#125;&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[LONG转JSON精度丢失]]></title>
    <url>%2F2018%2F01%2F14%2FLONG%E8%BD%ACJSON%E7%B2%BE%E5%BA%A6%E4%B8%A2%E5%A4%B1%2F</url>
    <content type="text"><![CDATA[1、前言对于Long 类型的数据，如果我们在Controller层通过@ResponseBody将返回数据自动转换成json时，不做任何处理，而直接传给前端的话，在Long长度大于17位时会出现精度丢失的问题。 至于为啥丢失，我们在此处不探讨。 如图所示：后端返回数据如下： 而前端接收的数据时就丢失了精度 2、简单分析首先，我们分析一下@ResponseBody是怎样将一个普通的对象转换成Json对象返回。 @responseBody注解的作用是将controller的方法返回的对象通过适当的转换器（默认使用MappingJackson2HttpMessageConverte（Spring 4.x以下使用的是MappingJackson2HttpMessageConverte））转换为指定的格式之后，写入到response对象的body区，需要注意的是，在使用此注解之后不会再走试图处理器，而是直接将数据写入到输入流中，他的效果等同于通过response对象输出指定格式的数据。 作用等同于response.getWriter.write(JSONObject.fromObject(user).toString()); 3、怎么处理总的来说主要有两种处理方式 如何避免精度丢失呢？最常用的办法就是待转化的字段统一转成String类型 那么怎样转化呢？ 一般有两种方式： 首先我们要在maven中添加必须的依赖 复制代码 ​ com.fasterxml.jackson.core​ jackson-annotations​ 2.8.6​ ​ ​ com.fasterxml.jackson.core​ jackson-databind​ 2.8.6​ 复制代码方式一. 1、在待转化的字段之上加上@JsonSerialize(using=ToStringSerializer.class)注解，如图所示： 复制代码@JsonInclude(JsonInclude.Include.NON_NULL)public class ProductVo { @JsonSerialize(using=ToStringSerializer.class) private Long productId private String productName; get,set省略 复制代码Controller方法不需要特殊处理,但是使用这种时，如果需要转换的字段较多，就显得比较繁琐。 让我们看看效果 方法二. 所以，我们可以采用配置spring的消息转换器的ObjectMapper为自定义的类 复制代码public class CustomObjectMapper extends ObjectMapper { public CustomObjectMapper() { super(); SimpleModule simpleModule = new SimpleModule(); simpleModule.addSerializer(Long.class, ToStringSerializer.instance); simpleModule.addSerializer(Long.TYPE, ToStringSerializer.instance); registerModule(simpleModule); } }复制代码然后，我们还需要在SpringMVC的配置文件中加上如下配置 复制代码&lt;mvc:annotation-driven &gt;​ mvc:message-converters​ ​ ​ ​ ​ application/json;charset=UTF-8​ text/plain;charset=UTF-8​ ​ ​ ​ &lt;-对日期进行转化的-&gt;​ ​ ​ ​ ​ ​ ​ ​ ​ ​ ​ ​ &lt;/mvc:message-converters&gt;​ &lt;/mvc:annotation-driven&gt;复制代码 至此就大功告成了，Controller方法不需要特殊处理，代码如下： 复制代码/*​ 跳转到首页​ @param request​ @param response​ */​ @RequestMapping(value=”/index”, method = RequestMethod.GET)​ public String page(HttpServletRequest request, HttpServletResponse response){​ return “/index”;​ } @RequestMapping(value = &quot;/getProducts&quot;,method = RequestMethod.POST) @ResponseBody public List getProducts(HttpServletRequest request,HttpServletResponse response){ List&lt;ProductVo&gt; productVos=new ArrayList&lt;&gt;(); for (int i=1;i&lt;=2;i++){ ProductVo productVo= new ProductVo(); productVo.setProductId(20170720125047233L+i); productVo.setProductName(&quot;测试商品&quot;+i); productVos.add(productVo); } return productVos; } @RequestMapping(value = &quot;/getUsers&quot;,method = RequestMethod.POST) @ResponseBody public List&lt;UserVo&gt; getUsers(){ List&lt;UserVo&gt; userVos=new ArrayList&lt;&gt;(); for (int i=1;i&lt;=2;i++){ UserVo userVo=new UserVo(); userVo.setUserid((long)i); userVo.setUserName(&quot;测试用户&quot;+i); userVo.setCreateTime(new Date()); userVos.add(userVo); } return userVos; } 复制代码 我们来看效果。]]></content>
  </entry>
  <entry>
    <title><![CDATA[log4j配置参数描述]]></title>
    <url>%2F2018%2F01%2F02%2Flog4j%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0%E6%8F%8F%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331# 可设置级别：TRACE→DEBUG→INFO→WARNING→ERROR→FATAL→OFF# 高级别level会屏蔽低级别level。# debug：显示debug、info、error# info：显示info、error#log4j.rootLogger=DEBUG,console,file log4j.rootLogger=INFO,console ​ ​ #输出到控制台 log4j.appender.console=org.apache.log4j.ConsoleAppender #设置输出样式 log4j.appender.console.layout=org.apache.log4j.PatternLayout #日志输出信息格式为 log4j.appender.console.layout.ConversionPattern=[%-d&#123;yyyy-MM-dd HH:mm:ss&#125;]-[%t-%5p]-[%C-%M(%L)]： %m%n #输出到文件(这里默认为追加方式) #log4j.appender.file=org.apache.log4j.FileAppender #log4j.appender.file.File=F:/LinkinPark/logs/Log4J.log #样式为TTCCLayout #log4j.appender.file.layout=org.apache.log4j.TTCCLayout #自定义样式 #%c 输出所属的类目，通常就是所在类的全名 #%C 输出Logger所在类的名称，通常就是所在类的全名 #%d 输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，比如：%d&#123;yyy MMM dd HH:mm:ss , SSS&#125;，%d&#123;ABSOLUTE&#125;，%d&#123;DATE&#125; #%F 输出所在类的类名称，只有类名。 #%l 输出语句所在的行数，包括类名+方法名+文件名+行数 #%L 输出语句所在的行数，只输出数字 #%m 输出代码中指定的讯息，如log(message)中的message #%M 输出方法名 #%p 输出日志级别，即DEBUG，INFO，WARN，ERROR，FATAL #%r 输出自应用启动到输出该log信息耗费的毫秒数 #%t 输出产生该日志事件的线程名 #%n 输出一个回车换行符，Windows平台为“/r/n”，Unix平台为“/n” #%% 用来输出百分号“%” #log4j.appender.Linkin.layout.ConversionPattern=%n[%l%d&#123;yy/MM/dd HH:mm:ss:SSS&#125;][%C-%M] %m #log4j.appender.Linkin.layout.ConversionPattern=%-d&#123;yyyy-MM-dd HH:mm:ss&#125;[%C]-[%p] %m%n #log4j.appender.Linkin.layout.ConversionPattern = %d&#123;ABSOLUTE&#125; %5p %t %c&#123;2&#125;:%L - %m%n ---log4j.properties 使用一.参数意义说明输出级别的种类ERROR、WARN、INFO、DEBUGERROR 为严重错误 主要是程序的错误WARN 为一般警告，比如session丢失INFO 为一般要显示的信息，比如登录登出DEBUG 为程序的调试信息配置日志信息输出目的地log4j.appender.appenderName = fully.qualified.name.of.appender.class1.org.apache.log4j.ConsoleAppender（控制台）2.org.apache.log4j.FileAppender（文件）3.org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件）4.org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生一个新的文件）5.org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方）配置日志信息的格式log4j.appender.appenderName.layout = fully.qualified.name.of.layout.class1.org.apache.log4j.HTMLLayout（以HTML表格形式布局），2.org.apache.log4j.PatternLayout（可以灵活地指定布局模式），3.org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串），4.org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等等信息）控制台选项Threshold=DEBUG:指定日志消息的输出最低层次。ImmediateFlush=true:默认值是true,意谓着所有的消息都会被立即输出。Target=System.err：默认情况下是：System.out,指定输出控制台FileAppender 选项Threshold=DEBUF:指定日志消息的输出最低层次。ImmediateFlush=true:默认值是true,意谓着所有的消息都会被立即输出。File=mylog.txt:指定消息输出到mylog.txt文件。Append=false:默认值是true,即将消息增加到指定文件中，false指将消息覆盖指定的文件内容。RollingFileAppender 选项Threshold=DEBUG:指定日志消息的输出最低层次。ImmediateFlush=true:默认值是true,意谓着所有的消息都会被立即输出。File=mylog.txt:指定消息输出到mylog.txt文件。Append=false:默认值是true,即将消息增加到指定文件中，false指将消息覆盖指定的文件内容。MaxFileSize=100KB: 后缀可以是KB, MB 或者是 GB. 在日志文件到达该大小时，将会自动滚动，即将原来的内容移到mylog.log.1文件。MaxBackupIndex=2:指定可以产生的滚动文件的最大数。log4j.appender.A1.layout.ConversionPattern=%-4r %-5p %d&#123;yyyy-MM-dd HH:mm:ssS&#125; %c %m%n日志信息格式中几个符号所代表的含义： -X号: X信息输出时左对齐； %p: 输出日志信息优先级，即DEBUG，INFO，WARN，ERROR，FATAL, %d: 输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，比如：%d&#123;yyy MMM dd HH:mm:ss,SSS&#125;，输出类似：2002年10月18日 22：10：28，921 %r: 输出自应用启动到输出该log信息耗费的毫秒数 %c: 输出日志信息所属的类目，通常就是所在类的全名 %t: 输出产生该日志事件的线程名 %l: 输出日志事件的发生位置，相当于%C.%M(%F:%L)的组合,包括类目名、发生的线程，以及在代码中的行数。举例：Testlog4.main (TestLog4.java:10) %x: 输出和当前线程相关联的NDC(嵌套诊断环境),尤其用到像java servlets这样的多客户多线程的应用中。 %%: 输出一个&quot;%&quot;字符 %F: 输出日志消息产生时所在的文件名称 %L: 输出代码中的行号 %m: 输出代码中指定的消息,产生的日志具体信息 %n: 输出一个回车换行符，Windows平台为&quot;\r\n&quot;，Unix平台为&quot;\n&quot;输出日志信息换行 可以在%与模式字符之间加上修饰符来控制其最小宽度、最大宽度、和文本的对齐方式。如： 1)%20c：指定输出category的名称，最小的宽度是20，如果category的名称小于20的话，默认的情况下右对齐。 2)%-20c:指定输出category的名称，最小的宽度是20，如果category的名称小于20的话，&quot;-&quot;号指定左对齐。 3)%.30c:指定输出category的名称，最大的宽度是30，如果category的名称大于30的话，就会将左边多出的字符截掉，但小于30的话也不会有空格。 4)%20.30c:如果category的名称小于20就补空格，并且右对齐，如果其名称长于30字符，就从左边较远输出的字符截掉。二.文件配置Sample1log4j.rootLogger=DEBUG,A1,R#log4j.rootLogger=INFO,A1,R# ConsoleAppender 输出log4j.appender.A1=org.apache.log4j.ConsoleAppenderlog4j.appender.A1.layout=org.apache.log4j.PatternLayoutlog4j.appender.A1.layout.ConversionPattern=%-d&#123;yyyy-MM-dd HH:mm:ss,SSS&#125; [%c]-[%p] %m%n# File 输出 一天一个文件,输出路径可以定制,一般在根路径下log4j.appender.R=org.apache.log4j.DailyRollingFileAppenderlog4j.appender.R.File=blog_log.txtlog4j.appender.R.MaxFileSize=500KBlog4j.appender.R.MaxBackupIndex=10log4j.appender.R.layout=org.apache.log4j.PatternLayoutlog4j.appender.R.layout.ConversionPattern=%d&#123;yyyy-MM-dd HH:mm:ss,SSS&#125; [%t] [%c] [%p] - %m%n文件配置Sample2下面给出的Log4J配置文件实现了输出到控制台，文件，回滚文件，发送日志邮件，输出到数据库日志表，自定义标签等全套功能。log4j.rootLogger=DEBUG,CONSOLE,A1,im #DEBUG,CONSOLE,FILE,ROLLING_FILE,MAIL,DATABASElog4j.addivity.org.apache=true################### # Console Appender ################### log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppender log4j.appender.Threshold=DEBUG log4j.appender.CONSOLE.Target=System.out log4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayout log4j.appender.CONSOLE.layout.ConversionPattern=[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n #log4j.appender.CONSOLE.layout.ConversionPattern=[start]%d&#123;DATE&#125;[DATE]%n%p[PRIORITY]%n%x[NDC]%n%t[THREAD] n%c[CATEGORY]%n%m[MESSAGE]%n%n##################### # File Appender ##################### log4j.appender.FILE=org.apache.log4j.FileAppender log4j.appender.FILE.File=file.log log4j.appender.FILE.Append=false log4j.appender.FILE.layout=org.apache.log4j.PatternLayout log4j.appender.FILE.layout.ConversionPattern=[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n # Use this layout for LogFactor 5 analysis######################## # Rolling File ######################## log4j.appender.ROLLING_FILE=org.apache.log4j.RollingFileAppender log4j.appender.ROLLING_FILE.Threshold=ERROR log4j.appender.ROLLING_FILE.File=rolling.log log4j.appender.ROLLING_FILE.Append=true log4j.appender.ROLLING_FILE.MaxFileSize=10KB log4j.appender.ROLLING_FILE.MaxBackupIndex=1 log4j.appender.ROLLING_FILE.layout=org.apache.log4j.PatternLayout log4j.appender.ROLLING_FILE.layout.ConversionPattern=[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n#################### # Socket Appender #################### log4j.appender.SOCKET=org.apache.log4j.RollingFileAppender log4j.appender.SOCKET.RemoteHost=localhost log4j.appender.SOCKET.Port=5001 log4j.appender.SOCKET.LocationInfo=true # Set up for Log Facter 5 log4j.appender.SOCKET.layout=org.apache.log4j.PatternLayout log4j.appender.SOCET.layout.ConversionPattern=[start]%d&#123;DATE&#125;[DATE]%n%p[PRIORITY]%n%x[NDC]%n%t[THREAD]%n%c[CATEGORY]%n%m[MESSAGE]%n%n######################## # Log Factor 5 Appender ######################## log4j.appender.LF5_APPENDER=org.apache.log4j.lf5.LF5Appender log4j.appender.LF5_APPENDER.MaxNumberOfRecords=2000######################## # SMTP Appender ####################### log4j.appender.MAIL=org.apache.log4j.net.SMTPAppender log4j.appender.MAIL.Threshold=FATAL log4j.appender.MAIL.BufferSize=10 log4j.appender.MAIL.From=chenyl@yeqiangwei.comlog4j.appender.MAIL.SMTPHost=mail.hollycrm.com log4j.appender.MAIL.Subject=Log4J Message log4j.appender.MAIL.To=chenyl@yeqiangwei.comlog4j.appender.MAIL.layout=org.apache.log4j.PatternLayout log4j.appender.MAIL.layout.ConversionPattern=[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n######################## # JDBC Appender ####################### log4j.appender.DATABASE=org.apache.log4j.jdbc.JDBCAppender log4j.appender.DATABASE.URL=jdbc:mysql://localhost:3306/test log4j.appender.DATABASE.driver=com.mysql.jdbc.Driver log4j.appender.DATABASE.user=root log4j.appender.DATABASE.password= log4j.appender.DATABASE.sql=INSERT INTO LOG4J (Message) VALUES (&apos;[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n&apos;) log4j.appender.DATABASE.layout=org.apache.log4j.PatternLayout log4j.appender.DATABASE.layout.ConversionPattern=[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%nlog4j.appender.A1=org.apache.log4j.DailyRollingFileAppender log4j.appender.A1.File=SampleMessages.log4j log4j.appender.A1.DatePattern=yyyyMMdd-HH&apos;.log4j&apos; log4j.appender.A1.layout=org.apache.log4j.xml.XMLLayout################### #自定义Appender ################### log4j.appender.im = net.cybercorlin.util.logger.appender.IMAppenderlog4j.appender.im.host = mail.cybercorlin.net log4j.appender.im.username = username log4j.appender.im.password = password log4j.appender.im.recipient = corlin@yeqiangwei.comlog4j.appender.im.layout=org.apache.log4j.PatternLayout log4j.appender.im.layout.ConversionPattern =[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n三.高级使用实验目的： 1.把FATAL级错误写入2000NT日志 2. WARN，ERROR，FATAL级错误发送email通知管理员 3.其他级别的错误直接在后台输出实验步骤： 输出到2000NT日志 1.把Log4j压缩包里的NTEventLogAppender.dll拷到WINNT\SYSTEM32目录下 2.写配置文件log4j.properties# 在2000系统日志输出 log4j.logger.NTlog=FATAL, A8 # APPENDER A8 log4j.appender.A8=org.apache.log4j.nt.NTEventLogAppender log4j.appender.A8.Source=JavaTest log4j.appender.A8.layout=org.apache.log4j.PatternLayout log4j.appender.A8.layout.ConversionPattern=%-4r %-5p [%t] %37c %3x - %m%n3.调用代码： Logger logger2 = Logger.getLogger(&quot;NTlog&quot;); //要和配置文件中设置的名字相同 logger2.debug(&quot;debug!!!&quot;); logger2.info(&quot;info!!!&quot;); logger2.warn(&quot;warn!!!&quot;); logger2.error(&quot;error!!!&quot;); //只有这个错误才会写入2000日志 logger2.fatal(&quot;fatal!!!&quot;);发送email通知管理员： 1. 首先下载JavaMail和JAF, http://java.sun.com/j2ee/ja/javamail/index.html http://java.sun.com/beans/glasgow/jaf.html 在项目中引用mail.jar和activation.jar。 2. 写配置文件 # 将日志发送到email log4j.logger.MailLog=WARN,A5 # APPENDER A5 log4j.appender.A5=org.apache.log4j.net.SMTPAppender log4j.appender.A5.BufferSize=5 log4j.appender.A5.To=chunjie@yeqiangwei.com log4j.appender.A5.From=error@yeqiangwei.com log4j.appender.A5.Subject=ErrorLog log4j.appender.A5.SMTPHost=smtp.263.net log4j.appender.A5.layout=org.apache.log4j.PatternLayout log4j.appender.A5.layout.ConversionPattern=%-4r %-5p [%t] %37c %3x - %m%n 3.调用代码： //把日志发送到mail Logger logger3 = Logger.getLogger(&quot;MailLog&quot;); logger3.warn(&quot;warn!!!&quot;); logger3.error(&quot;error!!!&quot;); logger3.fatal(&quot;fatal!!!&quot;);在后台输出所有类别的错误： 1. 写配置文件 # 在后台输出 log4j.logger.console=DEBUG, A1 # APPENDER A1 log4j.appender.A1=org.apache.log4j.ConsoleAppender log4j.appender.A1.layout=org.apache.log4j.PatternLayout log4j.appender.A1.layout.ConversionPattern=%-4r %-5p [%t] %37c %3x - %m%n 2．调用代码 Logger logger1 = Logger.getLogger(&quot;console&quot;); logger1.debug(&quot;debug!!!&quot;); logger1.info(&quot;info!!!&quot;); logger1.warn(&quot;warn!!!&quot;); logger1.error(&quot;error!!!&quot;); logger1.fatal(&quot;fatal!!!&quot;);-------------------------------------------------------------------- 全部配置文件：log4j.properties # 在后台输出 log4j.logger.console=DEBUG, A1 # APPENDER A1 log4j.appender.A1=org.apache.log4j.ConsoleAppender log4j.appender.A1.layout=org.apache.log4j.PatternLayout log4j.appender.A1.layout.ConversionPattern=%-4r %-5p [%t] %37c %3x - %m%n# 在2000系统日志输出 log4j.logger.NTlog=FATAL, A8 # APPENDER A8 log4j.appender.A8=org.apache.log4j.nt.NTEventLogAppender log4j.appender.A8.Source=JavaTest log4j.appender.A8.layout=org.apache.log4j.PatternLayout log4j.appender.A8.layout.ConversionPattern=%-4r %-5p [%t] %37c %3x - %m%n# 将日志发送到email log4j.logger.MailLog=WARN,A5 # APPENDER A5 log4j.appender.A5=org.apache.log4j.net.SMTPAppender log4j.appender.A5.BufferSize=5 log4j.appender.A5.To=chunjie@yeqiangwei.com log4j.appender.A5.From=error@yeqiangwei.com log4j.appender.A5.Subject=ErrorLog log4j.appender.A5.SMTPHost=smtp.263.net log4j.appender.A5.layout=org.apache.log4j.PatternLayout log4j.appender.A5.layout.ConversionPattern=%-4r %-5p [%t] %37c %3x - %m%n全部代码：Log4jTest.java/* * 创建日期 2003-11-13 */ package edu.bcu.Bean; import org.apache.log4j.*; //import org.apache.log4j.nt.*; //import org.apache.log4j.net.*; /** * @author yanxu */ public class Log4jTest &#123; public static void main(String args[]) &#123; PropertyConfigurator.configure(&quot;log4j.properties&quot;); //在后台输出 Logger logger1 = Logger.getLogger(&quot;console&quot;); logger1.debug(&quot;debug!!!&quot;); logger1.info(&quot;info!!!&quot;); logger1.warn(&quot;warn!!!&quot;); logger1.error(&quot;error!!!&quot;); logger1.fatal(&quot;fatal!!!&quot;);//在NT系统日志输出 Logger logger2 = Logger.getLogger(&quot;NTlog&quot;); //NTEventLogAppender nla = new NTEventLogAppender(); logger2.debug(&quot;debug!!!&quot;); logger2.info(&quot;info!!!&quot;); logger2.warn(&quot;warn!!!&quot;); logger2.error(&quot;error!!!&quot;); //只有这个错误才会写入2000日志 logger2.fatal(&quot;fatal!!!&quot;);//把日志发送到mail Logger logger3 = Logger.getLogger(&quot;MailLog&quot;); //SMTPAppender sa = new SMTPAppender(); logger3.warn(&quot;warn!!!&quot;); logger3.error(&quot;error!!!&quot;); logger3.fatal(&quot;fatal!!!&quot;); &#125; &#125;]]></content>
  </entry>
</search>
